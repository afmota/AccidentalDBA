<!DOCTYPE html>
<html lang="pt-br">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>DBA Acidental</title>
</head>
<body>
    <h1>Capítulo 3: Utilização Elevada da CPU</h1>
    <p>Um sistema dependente da CPU é relativamente fácil de identificar, mas nem sempre é tão fácil de diagnosticar. Se você perceber que uma ou mais CPUs estão trabalhando próximo à capacidade máxima, juntamente com uma diminuição drástica no desempenho do servidor, então provavelmente há um problema com a CPU. A CPU está envolvida em quase todas as atividades do SQL Server, desde a execução de consultas até a movimentação de dados dentro e fora da memória, e assim por diante, o que significa que uma CPU sobrecarregada pode ter consequências graves.</p>
    <p>Infelizmente, a origem da pressão sobre a CPU nem sempre é fácil de identificar, uma vez que o que parece ser um problema da CPU pode ter sua causa raiz em outro lugar, como memória insuficiente, fazendo com que o SQL Server mova constantemente os dados dentro e fora da memória, consultas mal escritas, indexação inadequada ou até mesmo configurações inapropriadas de opções de configuração. A fonte da pressão sobre a CPU também pode ser um processo não relacionado ao SQL Server em execução no servidor.</p>
    <p>Independentemente do que tenha causado o problema, o objetivo da fase de investigação para solucionar a utilização excessiva da CPU no SQL Server é isolar o problema em uma fonte específica. Geralmente, isso exigirá a coleta de várias informações, usando ferramentas como o Monitor de Desempenho (PerfMon), SQLTrace e várias das Visualizações de Gerenciamento Dinâmico do SQL Server.</p>
    <p>Uma vez confirmado que o alto uso da CPU é devido ao processo do SQL Server, e o problema foi isolado para uma consulta específica (ou conjunto de consultas), podemos buscar aliviar a pressão da CPU por meio de mudanças no design, como ajustar consultas que consomem muita CPU, adicionar índices apropriados, substituir consultas SQL improvisadas por stored procedures para melhorar a reutilização de planos e assim por diante, ou ajustar as configurações de configuração do SQL Server e do Windows.</p>
    <h2>Investigando a Pressão da CPU</h2>
    <p>Nesta seção, discutiremos as três principais ferramentas usadas para medir o uso da CPU e diagnosticar a pressão da CPU no SQL Server:</p>
    <ul>
        <li><strong>Performance Monitor</strong> - uma ferramenta de monitoramento do Windows para medir o uso da CPU pelo SQL Server e outros processos em execução no servidor.</li>
        <li><strong>SQLTrace</strong> - um conjunto de stored procedures do sistema para rastrear eventos em tempo real que estão sendo executados no SQL Server durante períodos de alto uso da CPU.</li>
        <li><strong>Dynamic Management Views</strong> - uma coleção de objetos do sistema que fornecem dados instantâneos e agregados sobre o uso de recursos no SQL Server.</li>
    </ul>
    <h3>Performance Monitor</h3>
    <p>Se o seu sistema SQL Server estiver enfrentando uma atividade excessivamente alta da CPU, a primeira ferramenta à qual você deve recorrer é o <strng>Performance Monitor</strng> (PerfMon). Essa ferramenta de monitoramento do Windows irá confirmar se o uso excessivo da CPU é devido à atividade do SQL Server ou se é causado por outros processos no servidor ou pelo próprio sistema operacional. Não faz sentido gastar tempo e energia valiosos investigando o SQL Server por uso excessivo da CPU se a causa raiz for um processo não relacionado ao SQL Server.</p>
    <p>Os principais contadores do PerfMon que são úteis para monitorar o uso da CPU são listados abaixo com breves explicações (citadas do MSDN):</p>
    <ul>
        <li><strong>Processor/ %Privileged Time</strong> - <em>porcentagem de tempo que o processador gasta na execução de comandos do kernel do Microsoft Windows, como atividade principal do sistema operacional e drivers de dispositivos.</em></li>
        <li><strong>Processor/ %User Time</strong> - <em>porcentagem de tempo que o processador gasta executando processos do usuário, como o SQL Server. Isso inclui solicitações de E/S do SQL Server.</em></li>
        <li><strong>Process (sqlservr.exe)/ %Processor Time</strong> - <em>a soma do tempo do processador em cada processador para todos os threads do processo.</em></li>
    </ul>
    <p>Basta abrir o PerfMon (<strong>Painel de Controle | Sistema e Segurança | Ferramentas Administrativas</strong>), clicar no botão <strong>Adicionar</strong> (representado por uma cruz verde) e adicionar os contadores, conforme mostrado na Figura 3.1.</p>
    <img src="imagens/addcounters.PNG" alt="Adicionando contadores">
    <p><strong>Figura 3.1</strong>: Adicionando contadores de CPU no PerfMon.</p>
    <p>Esses três contadores são suficientes para monitorar o uso geral da CPU, bem como o uso pelo SQL Server. No entanto, existem vários contadores de <code>SQL Statistics</code> (e um contador de Cache de Plano) que não monitoram diretamente o uso da CPU, mas monitoram eventos como eventos de compilação e recompilação, que podem consumir muitos ciclos de CPU ou são indicações de problemas que causam alto uso da CPU. Esses contadores são simplesmente listados aqui e discutidos em mais detalhes posteriormente no capítulo, em relação direta com os problemas que eles podem ser usados para investigar.</p>
    <ul>
        <li><strong>SQLServer:SQL Statistics/Auto-Param Attempts/sec</strong></li>
        <li><strong>SQLServer:SQL Statistics/Failed Auto-params/sec</strong></li>
        <li><strong>SQLServer:SQL Statistics/Batch Requests/sec</strong></li>
        <li><strong>SQLServer:SQL Statistics/SQL Compilations/sec</strong></li>
        <li><strong>SQLServer:SQL Statistics/SQL Re-Compilations/sec</strong></li>
        <li><strong>SQLServer:Plan Cache/Cache hit Ratio</strong></li>
    </ul>
    <p>Nenhum desses contadores possui limites rígidos que indicam valores "bons" ou "ruins"; em vez disso, eles devem ser avaliados em relação ao que é considerado normal para o sistema em questão, e se um determinado valor estiver muito fora da faixa normal, a causa deve ser investigada mais a fundo.</p>
    <p><strong><em>Uso do processador em máquinas virtuais</em></strong></p>
    <p><em>Em uma máquina virtual (VM), o </em><code>%ProcessorTime</code> <em>é a porcentagem dos recursos alocados para a VM que está sendo utilizada, e não a porcentagem alocada ao hardware real. Portanto, se a VM tiver sido alocada com recursos de CPU muito mínimos, o PerfMon pode mostrar um </em><code>%ProcessorTime</code> <em>muito alto, mesmo que as CPUs reais estejam sendo pouco utilizadas. Um dos primeiros passos ao investigar alto uso da CPU em uma máquina virtual é verificar o uso de hardware da máquina virtual como um todo e garantir que as alocações de recursos sejam razoáveis.</em></p>
    <h3>SQL Trace</h3>
    <p>A ferramenta Profiler incluída no SQL Server pode ser usada para examinar os detalhes dos comandos que estão sendo executados em um servidor SQL. É uma ferramenta útil para investigar os detalhes de problemas específicos depois que o problema geral foi identificado. A interface gráfica do Profiler faz uso de um conjunto de stored procedures, conhecidas coletivamente como <strong>SQL Trace</strong>. A própria interface gráfica deve ser usada com cautela em servidores mais movimentados, pois pode ter um efeito adverso no desempenho geral e na estabilidade do servidor. Em vez disso, deve-se executar um trace no lado do servidor, com a saída direcionada para um arquivo em uma unidade local rápida.</p>
    <p>O principal uso do SQL Trace é identificar consultas específicas que estão consumindo grandes quantidades de CPU. É menos útil para uma análise pontual do que as Dynamic Management Views, sendo mais útil para capturar cargas de trabalho para análise. Com as Dynamic Management Views (como <code>sys.dm_exec_requests</code>), é possível acompanhar o aumento do uso de recursos enquanto a consulta ainda está em execução, enquanto com o SQL Trace, a instrução ou lote deve ser concluído antes que o evento que mostra o uso total de recursos seja acionado.</p>
    <p>Para capturar um conjunto de consultas que estão usando quantidades excessivas de CPU, é necessário executar um trace durante períodos de alto uso da CPU. Os detalhes sobre como configurar e executar um trace são apresentados no <em>Capítulo 5</em> e não serão repetidos aqui. A consideração adicional ao executar um trace para investigar consultas que consomem grandes quantidades de <strong>CPU</strong> é adicionar um filtro na coluna de CPU para evitar capturar um grande número de consultas sem interesse.</p>
    <h3>Dynamic Management Views (DMVs)</h3>
    <p>Várias Dynamic Management Views (DMVs) fornecem uma variedade de informações que podem ajudar a diagnosticar problemas relacionados à CPU. Essas informações incluem estatísticas de desempenho agregadas das consultas, estatísticas de espera agregadas, detalhes do que está sendo executado, o que está esperando tempo de processamento, o que está esperando por outros recursos e outras informações que são difíceis ou impossíveis de obter de outra forma. Podemos investigar o alto uso da CPU pelo SQL Server examinando as estatísticas de espera relacionadas à CPU, os detalhes do escalonador e as estatísticas de desempenho agregadas das consultas, da seguinte forma:</p>
    <ul>
        <li>Verificar a extensão da pressão da CPU por meio de esperas de sinal, usando <code>sys.dm_os_wait_stats</code>.</li>
        <li>Diagnosticar um sistema com restrição de CPU de acordo com os tipos de espera observados, usando <code>sys.dm_os_wait_stats e sys.dm_os_schedulers</code>.</li>
        <li>Identificar planos em cache com alto uso de CPU e consultas associadas, usando <code>sys.dm_exec_query_stats e sys.dm_exec_sql_text</code>.</li>
        <li>Identificar tarefas atualmente em espera, especialmente aquelas que estão esperando por tipos de espera relacionados à CPU, usando <code>sys.dm_os_waiting_tasks</code>.</li>
        <li>Observar o uso de recursos das consultas em execução atualmente com <code>sys.dm_exec_requests</code>.</li>
    </ul>
    <h2>Investigando estatísticas de espera relacionadas à CPU</h2>
    <p>Sempre que uma sessão precisa esperar antes que o trabalho solicitado possa continuar, o SQL Server registra o motivo da espera (o recurso pelo qual está esperando) e o tempo de espera. A DMV <code>sys.dm_os_wait_stats</code> expõe essas estatísticas de espera, agregadas em todas as sessões desde a última reinicialização do servidor ou desde a última vez em que as estatísticas de espera foram apagadas com o comando <code>DBCC SQLPERF('sys.dm_os_wait_stats', CLEAR)</code>. Essa DMV pode ser usada, entre outras coisas, para confirmar a pressão da CPU e estabelecer os tipos de espera mais comuns que um sistema com restrição de CPU está enfrentando.</p>
    <p>Vale ressaltar que algumas ferramentas de monitoramento de terceiros dependem das estatísticas nesta DMV não serem apagadas entre reinicializações do servidor, pois, se forem apagadas, isso pode afetar a precisão das informações exibidas por essas ferramentas de monitoramento.</p>
    <h3>Tempo de espera do sinal</h3>
    <p>Junto com uma coluna <code>wait_type</code>, que indica o tipo de espera, o DMV <code>sys.dm_os_wait_stats</code> retorna vários tempos de espera úteis, incluindo:</p>
    <ul>
        <li><strong><code>wait_time_ms</code></strong> - quantidade total de tempo que as tarefas esperaram por este determinado tipo de espera; esse valor inclui o tempo na coluna <code>signal_wait_time_ms</code>. O valor aumenta a partir do momento em que uma tarefa interrompe a execução para esperar por um recurso até o momento em que ela retoma a execução.</li>
        <li><strong><code>signal_wait_time_ms</code></strong> - a quantidade total de tempo que as tarefas levam para começar a executar após serem sinalizadas (ou seja, após o recurso pelo qual estavam esperando estar disponível); esse é o tempo gasto na fila de execução e é uma espera puramente da CPU.</li>
    </ul>
    <p>Se o tempo de espera do sinal for uma parte significativa do tempo total de espera, significa que as tarefas estão aguardando um tempo relativamente longo para retomar a execução após os recursos pelos quais estavam esperando ficarem disponíveis. Isso pode indicar que há muitas consultas intensivas de CPU, que podem precisar de otimização, ou que o servidor precisa de mais CPU. A consulta no Exemplo 3.1 fornecerá uma medida de quanto do tempo total de espera é o tempo de espera do sinal.</p>
    <pre>
        <code>
SELECT  SUM(signal_wait_time_ms) AS TotalSignalWaitTime ,
        ( SUM(CAST(signal_wait_time_ms AS NUMERIC(20, 2)))
          / SUM(CAST(wait_time_ms AS NUMERIC(20, 2))) * 100 )
                         AS PercentageSignalWaitsOfTotalTime
FROM    sys.dm_os_wait_stats
        </code>
    </pre>
    <p><strong>Exemplo 3.1</strong>: Verificando a pressão da CPU por meio do tempo de espera do sinal.</p>
    <p>Como esta exibição de gerenciamento de espera (DMV) mostra tempos de espera e contagens agregadas desde que as estatísticas foram zeradas ou desde que o servidor foi iniciado, uma visualização pontual das estatísticas de espera geralmente não é muito útil. O que é mais útil é comparar as estatísticas de espera em um determinado momento com as estatísticas em um momento anterior e ver como elas mudaram. A outra opção é zerar as estatísticas de espera da DMV, usando <code>DBCC SQLPERF("sys.dm_os_wait_stats",CLEAR);</code>, esperar um pouco e, em seguida, fazer consultas para ver o que se acumulou nesse período de tempo conhecido e definido.</p>
    <p><strong><em>Acompanhando esperas em nível de sessão e instrução</em></strong></p>
    <p><em>Como os tempos de espera nesta DMV são agregados, é difícil relacionar um tempo de espera a uma consulta específica, a menos que você esteja em um sistema de teste com apenas uma sessão em execução. No entanto, no SQL Server 2008, é possível fazer isso se você usar Eventos Estendidos (Extended Events). Veja o meu artigo no blog: <a href="http://sqlblog.com/blogs/jonathan_kehayias/archive/2010/12/30/an-xevent-a-day-30-of-31-tracking-session-and-statement-level-waits.aspx" target="_blank" rel="external">http://sqlblog.com/blogs/jonathan_kehayias/archive/2010/12/30/an-xevent-a-day-30-of-31-tracking-session-and-statement-level-waits.aspx</a>.</em></p>
    <p>Também podemos usar a DMV <code>sys.dm_os_wait_stats</code> para descobrir quais são as esperas de recursos mais comuns em nosso sistema com restrição de CPU, como mostrado no Exemplo 3.2, onde identificamos os principais eventos de espera, ordenados de acordo com a quantidade total de tempo que os processos esperaram (<code>wait_time_ms</code>) nesse evento. É importante ignorar as esperas benignas, normalmente causadas por processos do sistema que se espera que estejam esperando a maior parte do tempo. Também estamos subtraindo o <code>signal_wait_time</code>, pois essa parte do tempo de espera não está esperando pelo recurso específico, mas esperando por tempo no agendador.</p>
    <pre>
        <code>
SELECT TOP ( 10 )
        wait_type ,
        waiting_tasks_count ,
        ( wait_time_ms - signal_wait_time_ms ) AS resource_wait_time ,
        max_wait_time_ms ,
        CASE waiting_tasks_count
          WHEN 0 THEN 0
          ELSE wait_time_ms / waiting_tasks_count
        END AS avg_wait_time
FROM    sys.dm_os_wait_stats
WHERE   wait_type NOT LIKE '%SLEEP%' -- remove eg. SLEEP_TASK and
                                     -- LAZYWRITER_SLEEP waits
        AND wait_type NOT LIKE 'XE%'
        AND wait_type NOT IN -- remove system waits
( 'KSOURCE_WAKEUP', 'BROKER_TASK_STOP', 'FT_IFTS_SCHEDULER_IDLE_WAIT',
  'SQLTRACE_BUFFER_FLUSH', 'CLR_AUTO_EVENT', 'BROKER_EVENTHANDLER',
  'BAD_PAGE_PROCESS', 'BROKER_TRANSMITTER', 'CHECKPOINT_QUEUE',
  'DBMIRROR_EVENTS_QUEUE', 'SQLTRACE_BUFFER_FLUSH', 'CLR_MANUAL_EVENT',
  'ONDEMAND_TASK_QUEUE', 'REQUEST_FOR_DEADLOCK_SEARCH', 'LOGMGR_QUEUE',
  'BROKER_RECEIVE_WAITFOR', 'PREEMPTIVE_OS_GETPROCADDRESS',
  'PREEMPTIVE_OS_AUTHENTICATIONOPS', 'BROKER_TO_FLUSH' )
ORDER BY wait_time_ms DESC
-- **** Author: Jonathan Kaheyias ****
        </code>
    </pre>
    <p><strong>Exemplo 3.2</strong>: Encontrando os 10 principais eventos de espera (cumulativos).</p>
    <p>Três tipos de espera interessantes para se observar, em relação à pressão da CPU, são <code>SOS_SCHEDULER_YIELD</code>, <code>CXPACKET</code> e <code>CMEMTHREAD</code>.</p>
    <h3>Esperas <code>SOS_SCHEDULER_YIELD</code></h3>
    <p>O agendador SQL é um agendador cooperativo de multitarefa. Isso significa que ele depende das consultas em execução para voluntariamente ceder a CPU após um determinado tempo de execução. Em contraste, o agendador do Windows é um agendador de multitarefa preemptivo, o que significa que ele remove as tarefas da CPU após um determinado tempo.</p>
    <p>Quando uma tarefa voluntariamente cede a CPU e começa a esperar para retomar a execução, o tipo de espera atribuído à tarefa é <code>SOS_SCHEDULER_YIELD</code>. A tarefa cedente volta para a fila de execução e outra tarefa recebe seu tempo alocado na CPU.</p>
    <p>Se os tempos de espera globais forem baixos, esse tipo de espera é benigno, indicando simplesmente que a consulta passou mais tempo do que o permitido na CPU sem precisar esperar por outros recursos (E/S de disco, bloqueios, latches, concessões de memória etc.).</p>
    <p>Se as consultas mostrarem tempos de espera elevados em <code>sys.dm_exec_requests</code> ou <code>sys.dm_os_waiting_tasks</code> para o tipo de espera <code>SOS_SCHEDULER_YIELD</code>, isso indica que a consulta é extremamente intensiva em CPU. Se houver tempos de espera elevados para esse tipo de espera em geral no servidor, pode indicar que há muitas consultas intensivas em CPU, que podem precisar de otimização, ou que o servidor precisa de mais CPU. A atividade do agendador pode ser investigada ainda mais usando a DMV <code>sys.dm_os_schedulers</code> (discutida em breve).</p>
    <h3>Esperas <code>CXPACKET</code></h3>
    <p>As esperas <code>CXPACKET</code> ocorrem durante a sincronização do iterador de troca do processador de consulta entre os workers, para uma consulta em execução em paralelo em vários processadores. Se o servidor hospeda um data warehouse ou um banco de dados de relatórios que recebe um baixo volume de consultas, mas processa grandes quantidades de dados, o paralelismo pode reduzir substancialmente o tempo necessário para executar essas consultas. No entanto, em contraste, se o servidor hospeda um banco de dados OLTP que possui muitas consultas e transações pequenas, o paralelismo pode afetar negativamente o throughput e o desempenho. Para mais discussão sobre esperas <code>CXPACKET</code> elevadas e como lidar com esse problema, consulte a seção <em>Paralelismo inadequado</em>, posteriormente.</p>
    <h3>Esperas <code>CMEMTHREAD</code></h3>
    <p>As esperas <code>CMEMTHREAD</code> são esperas por objetos de memória sincronizados. Alguns objetos de memória podem ser acessados por vários threads simultaneamente, enquanto outros não podem. Quando vários threads tentam acessar um objeto de memória, normalmente um cache, que deve ser acessado por um thread de cada vez, os threads em espera recebem uma espera <code>CMEMTHREAD</code>.</p>
    <p>Em geral, as esperas <code>CMEMTHREAD</code> não são comuns ou duradouras. No entanto, há um problema de memória conhecido no SQL Server 2005, em que, sob certas circunstâncias, um servidor pode mostrar alto uso de CPU, esperas <code>CMEMTHREAD</code> muito altas e consultas com desempenho muito ruim. Os detalhes disso serão discutidos posteriormente, na seção <em>TokenAndPermUser-Store</em>.</p>
    <h2>Investigando as filas do agendador</h2>
    <p>A DMV <code>sys.dm_os_schedulers</code> pode identificar se uma instância do SQL está com restrição de CPU ou não. Esta DMV retorna uma linha para cada um dos agendadores do SQL Server e lista o número total de tarefas atribuídas a cada agendador, bem como o número que está pronto para execução.</p>
    <p>Uma tarefa pronta para execução é aquela que está nas filas de prontidão, esperando pelo tempo da CPU. Outras tarefas no agendador que estão no <code>current_tasks_count</code>, mas não no <code>runnable_tasks_count</code>, estão ou dormindo ou aguardando um recurso (bloqueio, latch, E/S, memória, etc.).</p>
    <pre>
        <code>
SELECT  scheduler_id ,
        current_tasks_count ,
        runnable_tasks_count
FROM    sys.dm_os_schedulers
WHERE   scheduler_id < 255
        </code>
    </pre>
    <p><strong>Exemplo 3.3</strong>: Investigando as filas do agendador.</p>
    <p>Novamente, não há um valor limite que represente a fronteira entre um número "bom" e "ruim" de tarefas prontas para execução, mas quanto menor, melhor. Um alto número de tarefas prontas para execução, assim como um alto tempo de espera do sinal, indica que não há CPU suficiente para a carga de consultas atual.</p>
    <p>O filtro para agendadores abaixo de 255 remove, do conjunto de resultados, os numerosos agendadores ocultos no SQL Server, que são usados para backups, a Conexão Administrativa Dedicada (DAC) e assim por diante, e não são de interesse ao investigar a carga geral da CPU.</p>
    <h2>Identificando consultas intensivas em CPU</h2>
    <p>Para determinar as consultas de pior desempenho no cache de plano do SQL Server, podem ser utilizadas as DMVs <code>sys.dm_exec_query_stats</code> e <code>sys.dm_exec_sql_text</code>. A DMV <code>sys.dm_exec_query_stats</code> fornece estatísticas agregadas e retorna uma linha para cada instrução de consulta no plano em cache. Muitas das colunas são contadores incrementais e fornecem informações sobre quantas vezes uma consulta foi executada e os recursos que foram utilizados. Por exemplo, as colunas <code>*_worker_time</code> representam o tempo gasto na CPU e as colunas <code>*_elapsed_time</code> mostram o tempo total de execução.</p>
    <p>A consulta mostrada no Exemplo 3.4 retorna as dez consultas mais custosas em cache pelo tempo total de CPU. Juntamos as funções <code>sys.dm_exec_sql_text</code> e <p>sys.dm_exec_query_plan</p> para recuperar o texto e os planos de execução dessas consultas, dentro do lote.</p>
    <pre>
        <code>
SELECT TOP ( 10 )
        SUBSTRING(ST.text, ( QS.statement_start_offset / 2 ) + 1,
                  ( ( CASE statement_end_offset
                        WHEN -1 THEN DATALENGTH(st.text)
                        ELSE QS.statement_end_offset
                    END - QS.statement_start_offset ) / 2 ) + 1)
                AS statement_text ,84
        execution_count ,
        total_worker_time / 1000 AS total_worker_time_ms ,
         ( total_worker_time / 1000 ) / execution_count
AS avg_worker_time_ms ,
total_logical_reads ,
total_logical_reads / execution_count AS avg_logical_reads ,
total_elapsed_time / 1000 AS total_elapsed_time_ms ,
( total_elapsed_time / 1000 ) / execution_count
AS avg_elapsed_time_ms ,
qp.query_plan
FROM sys.dm_exec_query_stats qs
CROSS APPLY sys.dm_exec_sql_text(qs.sql_handle) st
CROSS APPLY sys.dm_exec_query_plan(qs.plan_handle) qp
ORDER BY total_worker_time DESC
        </code>
    </pre>
    <p><strong>Listagem 3.4</strong>: Encontrando as dez consultas que consomem mais CPU.</p>
    <p>O plano de execução pode ser visualizado clicando no link XML para abrir o plano em sua forma gráfica. O plano de execução retornado é para o lote inteiro, não apenas para a declaração de alto consumo de CPU.</p>
    <p>Ao consultar o cache de planos para investigar planos subótimos, observe que algumas consultas podem não ser listadas. Os planos de execução são retidos em cache até que o SQL Server decida que o plano envelheceu a ponto de ser removido para permitir que novos planos de execução sejam armazenados em cache, ou o cache é totalmente ou parcialmente limpo por comandos <code>DBCC</code>, alterações no estado do banco de dados (restauração de um banco de dados, desanexação ou colocação de um banco de dados offline, etc.) ou determinadas alterações de configuração em todo o servidor, ou o SQL Server é reiniciado. O SQL Server também removerá os planos de execução do cache se ele encontrar que memória extra é necessária em outros lugares do sistema.</p>
    <p><strong><em>Limpando o cache de planos</em></strong></p>
    <p><em>Você pode limpar todos os planos do cache usando</em> <code>DBCC FREEPROCCACHE</code><em>, ou fornecer um</em> <code>plan_handle</code> <em>ou </em><code>sql_handle</code> <em>para remover um plano de um lote específico. Alternativamente,</em> <code>DBCC FREEPROCINDB(db_id)</code> <em>pode ser usado para remover planos deuma base de dados específica.</em></p>
    <p>Também é importante observar que algumas consultas podem nunca aparecer no cache. Procedimentos marcados com <code>WITH RECOMPILE</code> e consultas com a dica <code>OPTION (RECOMPILE)</code> nunca são armazenados em cache. Além disso, as estatísticas da consulta são apagadas quando a consulta é recompilada por qualquer motivo, como alterações nas estatísticas ou no esquema. Como resultado, consultas que estão sujeitas a muitos eventos de recompilação também podem mostrar um tempo total muito baixo de execução, pois esse total se refere apenas ao plano atual, que pode não ter sido armazenado em cache por muito tempo.</p>
    <p>Esse problema vai além da recompilação; os resultados que você obtém de consultas como a Listagem 3.4 serão distorcidos em favor dos planos que estiveram no cache por mais tempo. Um plano frequentemente utilizado que esteve no cache por muito tempo aparecerá mais acima na lista do que um plano realmente ruim que tenha sido adicionado recentemente ao cache.</p>
    <p>Ainda é possível ter uma boa ideia das consultas que foram executadas e como foram executadas, mas a única maneira de garantir uma análise verdadeiramente imparcial é limpar o cache e depois realizar a análise após um período de tempo definido. No entanto, limpar o cache em um servidor de produção pode não ser a melhor ideia, especialmente se esse servidor já estiver conhecido por ter restrições de CPU. Por isso, se uma análise abrangente for necessária, recomendo o uso de rastreamento no lado do servidor para capturar todas as consultas em execução durante um determinado período de tempo.</p>
    <h2>Causas comuns de alto uso de CPU</h2>
    <p>Independentemente do tamanho e custo do hardware e tecnologia que sustentam suas instalações do SQL Server, sempre há o risco de uma ou mais declarações T-SQL mal ajustadas causarem uma utilização excessiva dos recursos.</p>
    <p>Para cada declaração enviada ao SQL Server para execução, o otimizador de consultas tenta encontrar a maneira mais eficiente de recuperar os dados, ou seja, aquela que utiliza menos recursos de CPU, E/S e memória. O plano gerado pelo otimizador será tão bom quanto os caminhos de acesso aos dados disponíveis e as informações que possui sobre os dados e sua distribuição. Se índices apropriados estiverem ausentes ou se as consultas forem escritas de forma a ignorar índices potencialmente úteis, o otimizador não conseguirá elaborar um plano verdadeiramente otimizado. Da mesma forma, se as estatísticas de índice que o otimizador possui sobre os dados forem imprecisas, o otimizador pode selecionar um plano subótimo, uma vez que as informações usadas para calcular o custo dos planos são imprecisas.</p>
    <p>Outra possibilidade é que o otimizador produza um plano que seja ótimo para uma execução da consulta (geralmente aquela que acionou a otimização) e não para outras execuções. Isso é comumente conhecido como "parameter sniffing", embora seja mais apropriado se referir a ele como "parameter sniffing inadequado", uma vez que o parameter sniffing em geral é algo bom, como discutiremos mais adiante no capítulo.</p>
    <h3>Índices ausentes</h3>
    <p>Pode surpreender algumas pessoas saber que índices ausentes podem causar alto uso de CPU, mas, na verdade, a falta de indexação apropriada é uma das causas mais comuns de alta utilização de CPU e E/S no SQL Server. Quando um índice apropriado não existe para satisfazer uma consulta, as leituras em tabela resultantes podem causar um uso significativo de CPU, já que o SQL precisa ler e processar muitas mais linhas do que o necessário para satisfazer a consulta.</p>
    <p>Usando os planos de execução obtidos no cache de planos, como mostrado na Listagem 3.4, podemos identificar quaisquer operações que podem ser substituídas por operações mais eficientes, adicionando índices de cobertura ou, em alguns casos, alterando os índices existentes. Vamos considerar uma consulta simples no banco de dados <code>Adventureworks2008</code>, como mostrado na Listagem 3.5.</p>
    <pre>
        <code>
SELECT  per.FirstName ,
        per.LastName ,
        p.Name ,
        p.ProductNumber ,
        OrderDate ,
        LineTotal ,
        soh.TotalDue
FROM    Sales.SalesOrderHeader AS soh
        INNER JOIN Sales.SalesOrderDetail sod
        ON soh.SalesOrderID = sod.SalesOrderID
        INNER JOIN Production.Product AS p ON sod.ProductID = p.ProductID
        INNER JOIN Sales.Customer AS c ON soh.CustomerID = c.CustomerID
        INNER JOIN Person.Person AS per
                      ON c.PersonID = per.BusinessEntityID
WHERE LineTotal > 25000
        </code>
    </pre>
    <p><strong>Listagem 3.5</strong>: Uma consulta simples no AdventureWorks.</p>
    <p>Esta consulta causa uma leitura completa da tabela SalesOrderDetail, pois não há um índice na coluna LineTotal. As características de execução (com todas as páginas necessárias no cache de dados, portanto, sem espera de E/S) são as seguintes:</p>
    <pre>
        <code>
SQL Server parse and compile time:
   CPU time = 0 ms, elapsed time = 0 ms.
SQL Server Execution Times:
   CPU time = 452 ms, elapsed time = 458 ms.
        </code>
    </pre>
    <p>Quase meio segundo de tempo de CPU para retornar 24 linhas; isso não é bom. Agora, vamos adicionar um índice simples, conforme mostrado na Listagem 3.6.</p>
    <pre>
        <code>
CREATE NONCLUSTERED INDEX idx_SalesOrderDetail_LineTotal
ON Sales.SalesOrderDetail (LineTotal)
        </code>
    </pre>
    <p><strong>Listagem 3.6</strong>: Adicionando um índice à coluna <code>LineTotal</code> no <code>AdventureWorks</code>.</p>
    <p>Agora, se executarmos a mesma consulta novamente, as características de desempenho serão muito diferentes:</p>
    <pre>
        <code>
SQL Server parse and compile time:
   CPU time = 0 ms, elapsed time = 0 ms.
SQL Server Execution Times:
   CPU time = 0 ms, elapsed time = 8 ms.
        </code>
    </pre>
    <p>Este foi um exemplo simplista, mas serve para demonstrar o ponto e um dos principais problemas que observo ao investigar cenários de alto uso de CPU é, simplesmente, a ausência de índices.</p>
    <p>Consulte o <em>Capítulo 5</em> para obter mais informações sobre índices ausentes.</p>
    <h3>Estatísticas desatualizadas</h3>
    <p>O Otimizador do SQL Server usa estatísticas para calcular a cardinalidade estimada para vários operadores de consulta. Essa cardinalidade, essencialmente o número de linhas, afeta o custo dos operadores. O custo dos operadores, por sua vez, determina o custo do plano. Se a estimativa de cardinalidade estiver incorreta, devido a estatísticas desatualizadas, o custo que o otimizador calcula para os operadores também estará incorreto, levando o otimizador a selecionar um plano que tem um custo estimado baixo, mas um custo real muito alto quando é executado.</p>
    <p>O efeito colateral mais comum de estatísticas incorretas é que o otimizador faz estimativas subestimadas para o número de linhas e, portanto, escolhe operadores que são muito eficientes para um pequeno número de linhas, como junções de loop aninhado e pesquisas de chave. Quando a consulta é executada e descobre-se que um grande número de linhas precisa ser processado, os operadores escolhidos não se adaptam bem e o plano se torna altamente ineficiente.</p>
    <p>Uma maneira de identificar se há um problema com as estatísticas de uma consulta específica é executar a consulta no Management Studio, retornar o plano de execução real e examinar as contagens estimadas e reais de linhas para quaisquer operações de busca e varredura de índice dentro do plano de execução. Se as duas contagens forem significativamente diferentes, considerando que a contagem estimada é por execução do operador e a contagem real é um total para todas as execuções do operador, então uma possibilidade é que as estatísticas estejam desatualizadas.</p>
    <p>Corrigir estatísticas desatualizadas é feito por meio da instrução <code>UPDATE STATISTICS</code>. Isso pode ser executado para todas as estatísticas em uma tabela (<code>UPDATE STATISTICS <nome da tabela></code>) ou apenas para um conjunto de estatísticas específico (<code>UPDATE STATISTICS <nome da tabela> <nome da estatística></code>).</p>
    <p>Se o problema for devido a estatísticas desatualizadas, ou seja, uma atualização das estatísticas resolve o problema, então você precisa evitar que o problema ocorra novamente, e existem três maneiras de fazer isso:</p>
    <ol>
        <li>Se a configuração do banco de dados "Auto_Update_Statistics" estiver desativada, considere ativá-la. Alternativamente, um trabalho de atualização de estatísticas em todo o banco de dados pode ser executado regularmente.</li>
        <li>Se as atualizações automáticas estiverem desabilitadas para um índice específico ou conjunto de estatísticas, como resultado da reconstrução do índice com a opção NORECOMPUTE, elas devem ser habilitadas.</li>
        <li>Um trabalho pode ser criado para atualizar as estatísticas específicas que sofrem com atualizações insuficientes e, consequentemente, resultam em problemas de desempenho. Esse trabalho pode ser agendado com a frequência necessária. Já ouvi falar de casos em que um trabalho desse tipo é executado a cada hora.</li>
    </ol>
    <h3>Predicados não-SARGáveis</h3>
    <p>SARGável, em que SARG significa Argumento de Busca, é um daqueles termos inventados irritantes que nós, como profissionais de TI, adoramos usar; simplesmente significa que um predicado pode ser usado em uma operação de busca de índice. As regras para predicados SARGáveis, em geral, são que a coluna deve ser comparada diretamente (igualdade ou desigualdade) a uma expressão, e qualquer função especificada na coluna tornará o predicado não-SARGável. Em outras palavras, <code>WHERE AlgumaFuncao(Coluna) = @Valor</code> não é SARGável, enquanto <code>WHERE Coluna = AlgumaOutraFuncao(@Valor)</code> é SARGável. Observe que a SARGabilidade não exclui o uso de operadores como <code>LIKE</code> ou <code>BETWEEN</code> (ambos são comparações de desigualdade) ou <code>IN</code> (tratado como um conjunto de comparações de igualdade).</p>
    <p>Predicados não-SARGáveis podem resultar em varreduras de tabela ou de índice e, assim como no caso de índices ausentes, isso causará um uso significativo de CPU, pois o SQL precisa ler e processar muito mais linhas do que o necessário. A Listagem 3.7 mostra um exemplo de um predicado da cláusula <code>WHERE</code> que é não-SARGável devido ao uso de algumas funções de manipulação de datas na coluna <code>ModifiedDate</code>. Este exemplo pressupõe que um índice tenha sido adicionado em <code>ModifiedDate</code>, já que não há um índice desse tipo no banco de dados padrão <code>AdventureWorks</code>.</p>
    <pre>
        <code>
SELECT  soh.SalesOrderID ,
        OrderDate ,
        DueDate ,
        ShipDate ,
        Status ,
        SubTotal ,
        TaxAmt ,
        Freight ,
        TotalDue
FROM    Sales.SalesOrderheader AS soh
        INNER JOIN Sales.SalesOrderDetail AS sod
                    ON soh.SalesOrderID = sod.SalesOrderID
WHERE   CONVERT(VARCHAR(10), sod.ModifiedDate, 101) = '01/01/2010'
        </code>
    </pre>
    <p><code>Listagem 3.7</code>: Um predicado não-SARGável na condição de busca.</p>
    <p>A partir do plano de execução, podemos ver que o uso das funções na coluna ModifiedDate impossibilitou a realização de uma operação de busca no índice; todo o índice foi escaneado para localizar os valores correspondentes, como mostrado na Figura 3.2.</p>
    <img src="imagens/fig32.PNG" alt="Index Scan">
    <p><strong>Figura 3.2</strong>: Um escaneamento de índice no índice SalesOrderDetail.</p>
    <p>Este é um problema bastante comum no código SQL. As datas podem ser difíceis de lidar e muitas vezes as pessoas optam pela abordagem mais fácil, sem perceber o impacto que terá no desempenho. A mudança neste caso é simples; modifique o predicado para ser uma busca de intervalo (desigualdade) por datas e horários dentro do dia desejado.</p>
    <pre>
        <code>
SELECT  soh.SalesOrderID ,
        OrderDate ,
        DueDate ,
        ShipDate ,
        Status ,
        SubTotal ,
        TaxAmt ,
        Freight ,
        TotalDue
FROM    Sales.SalesOrderheader AS soh
        INNER JOIN Sales.SalesOrderDetail AS sod ON soh.SalesOrderID = sod.SalesOrderID
WHERE sod.ModifiedDate >= '2010/01/01'
AND sod.ModifiedDate < '2010/01/02'
        </code>
    </pre>
    <p><strong>Listagem 3.8</strong>: Um predicado SARGável na condição de busca.</p>
    <p>A Figura 3.3 confirma que agora vemos uma operação de busca no índice.</p>
    <p>Esse é um problema bastante comum em muitos bancos de dados. Com frequência, vejo funções como <code>UPPER</code>, <code>LTRIM</code>, <code>ISNULL</code> sendo usadas em consultas, seja nos joins ou na cláusula <code>WHERE</code>, e em muitos casos simplesmente não há necessidade delas. Se as colunas usarem uma colação que não diferencia maiúsculas de minúsculas, os valores em maiúsculas e minúsculas são considerados iguais, e o uso das funções <code>UPPER</code> ou <code>LOWER</code> não faz nada além de degradar o desempenho. Da mesma forma, nas comparações de strings, o SQL ignora espaços finais, eliminando a necessidade da função <code>RTRIM</code>.</p>
    <img src="imagens/fig33.PNG" alt="Index Seek">
    <p><strong>Figura 3.3</strong>: Uma busca de índice no índice SalesOrderDetail.</p>
    
    Dealing with NULLs is always a fun one. The ISNULL function is often used unnecessarily due to a misunderstanding of how NULLs work in predicates. For example, the following two WHERE clause predicates are completely equivalent in function.

    WHERE ISNULL(SomeCol,0) > 0
    WHERE SomeCol > 0

    In the first one, any row with a NULL value will be excluded because the NULL is converted to zero and the filter is for values greater than zero. In the second one, any row with a NULL value will be excluded because NULLs do not ever return true when compared to any value using the =, <>, <, > or any of the other comparison operators. They can only return true for IS NULL or IS NOT NULL checks. Hence, both predicates achieve the same result, but only the second one allows use of index seeks.
    
    Implicit conversions

    An implicit conversion results from a comparison of unequal data types. SQL cannot compare values of differing types and it must convert one of the columns involved to the same data type as the other, in order to do the comparison.

    When an implicit conversion occurs on a column that is used in a WHERE or FROM clause, the SQL Server Optimizer dictates a conversion of all the column values before the filter can be applied. This means that, during the query execution, the query processor will convert the lower precedence data type to the higher precedence data type before applying the filter or join condition. This means that, as with the case of functions on the column, the predicate is considered non-SARGable and so index seeks cannot be used, SQL must process more rows than necessary to get the results, and this leads to higher CPU usage.

    A common manifestation of this problem is the comparison of NVARCHAR parameters to columns that are of type VARCHAR. There are some data access libraries (JDBC springs immediately to mind) that pass string constants as Unicode (NVARCHAR), by default. The problem is demonstrated in Listing 3.9, where the AccountNumber column is a VARCHAR and the parameter is a Unicode string (NVARCHAR), so designated by the N before the opening quote.

    SELECT  p.FirstName ,
            p.LastName ,
            c.AccountNumber
    FROM    Sales.Customer AS c
            INNER JOIN Person.Person AS p ON c.PersonID = p.BusinessEntityID
    WHERE   AccountNumber = N'AW00029594'

    Listing 3.9: An implicit data type conversion in the search condition.
    
    The relevant section of the execution plan, shown in Figure 3.4, confirms that we get an index scan operation.

    ********************************************************************
    * Figure 3.4: The non-SARGable predicate results in an index scan. *
    ********************************************************************

    The Filter properties window, in Figure 3.5, shows the implicit conversion.

    ***********************************************************************************************************************
    * Figure 3.5: The filter predicate dictates the need to convert all the rows in the AccountNumber column to NVARCHAR. *
    ***********************************************************************************************************************

    The fix for implicit conversions is to ensure that columns used in joins are always of the same type and that, in the WHERE clause, any variables, parameters or constants are of the same type as the columns to which they are being compared. If they are not, make careful use of conversion functions (CAST, CONVERT) on the variables, parameters or constants so that they match the data type of the column.

    If using data access libraries like JDBC, check the properties to ensure that they are not passing all string values as NVARCHAR regardless of the underlying column data type.

    Parameter sniffing

    Parameter sniffing is a process used by SQL Server when creating an execution plan for a stored procedure, function, or parameterized query. The first time the plan is compiled, SQL Server will examine, or "sniff", the input parameter values supplied, and use them, in conjunction with the column statistics, to estimate the number of rows that will be touched by the query. It then uses that estimate in its costing of various possible execution plans. A problem only arises if the values that were passed as input parameters on initial plan creation, result in a row count that is atypical of that which will result from future executions of the procedure. Parameter sniffing only occurs at the time a plan is compiled or recompiled, and all subsequent executions of the stored procedure, function, or parameterized query will use the same plan.

    During the initial compile, only the values of the input parameters can be sniffed as any local variables will have no value. If a statement within the batch is recompiled, both parameter and variable values can be sniffed, as the variables will, by that time, have values.

    By way of an example, we'll use the AdventureWorks database again, and specifically the ShipDate in the Sales.SalesOrderHeader table. This column has a minimum date of 2011/07/08 and maximum date of 2004/08/07. Listing 3.10 shows a stored procedure to find all sales order numbers (also in this table) that are between two given ship dates.

    CREATE PROCEDURE user_GetCustomerShipDates
        (
          @ShipDateStart DATETIME ,
          @ShipDateEnd DATETIME
        )
    AS
        SELECT  CustomerID ,
                SalesOrderNumber
        FROM    Sales.SalesOrderHeader
        WHERE   ShipDate BETWEEN @ShipDateStart AND @ShipDateEnd
    GO

    Listing 3.10: The user_GetCustomerShipDates stored procedure.

    This would be supported by a non-clustered index on ShipDate, as shown in Listing 3.11.

    CREATE NONCLUSTERED INDEX IDX_ShipDate_ASC
         ON Sales.SalesOrderHeader (ShipDate)
    GO

    Listing 3.11: A non-clustered index on the ShipDate column.

    Now, we'll execute the stored procedure twice, as shown in Listing 3.12, with the first query spanning a date range of several years, and so returning many rows, and the second one only covering a range of ten days. Be sure to retrieve the actual execution plan with the results.

    DBCC FREEPROCCACHE
    EXEC user_GetCustomerShipDates '2001/07/08', '2004/01/01'
    EXEC user_GetCustomerShipDates '2001/07/10', '2001/07/20'

    Listing 3.12: Executing the user_GetCustomerShipDates stored procedure, with the large date range query first.

    Note that we ran DBCC FREEPROCCACHE to clear the plan cache and ensure a new plan is created. The plan is identical in each case, as shown in Figure 3.6.

    ***********************************************************************************
    * Figure 3.6: Execution plans for the user_GetCustomerShipDates stored procedure. *
    ***********************************************************************************

    In the plan we see that optimizer has chosen not to use the non-clustered index on the ShipDate column, which we created especially for this procedure. The reason is that it is not a covering index (it doesn't include the SalesOrderNumber column) and the number of rows that the optimizer estimated, based on the parameter values for the initial execution, along with the statistics, was too high to make the combination of index seek/key lookup optimal. Hence the optimizer ignores that index and scans a different one.

    Now, run Listing 3.12 again, this time not returning the execution plan, but with STATISTICS IO and STATISTICS TIME enabled. The reason we're doing a separate run is that returning the actual execution has an impact on the query's performance, so executions that return the execution plan should not also be used to check the query's performance statistics. The results are as follows (the separating headers were added manually, for clarity).

    ==FIRST EXECUTION (LARGE DATE RANGE)===

    (Table 'SalesOrderHeader'. Scan count 1, logical reads 686, physical reads 0.

    SQL Server Execution Times:
      CPU time = 16 ms, elapsed time = 197 ms.

    SQL Server Execution Times:
      CPU time = 16 ms, elapsed time = 197 ms.

    ==SECOND EXECUTION (SMALL DATE RANGE)===

    Table 'SalesOrderHeader'. Scan count 1, logical reads 686, physical reads 0.

    SQL Server Execution Times:
      CPU time = 15 ms, elapsed time = 5 ms.

    SQL Server Execution Times:
      CPU time = 15 ms, elapsed time = 5 ms.

    The logical reads are shown as 686 reads for both, but it's the CPU time that is of far more interest here. It's worth noting that the majority of the elapsed time is actually the transmission and display of the rows, hence this time will be far larger for 17,000 rows (the first set) than for 40 rows (the second).

    Now, we'll clear the cache again and flip the order of execution, so the shorter date range query is executed first, as shown in Listing 3.13. This means that, this time, the parameter sniffing process will result in a much lower estimated number of rows.

    DBCC FREEPROCCACHE
    EXEC user_GetCustomerShipDates '2001/07/10', '2001/07/20'
    EXEC user_GetCustomerShipDates '2001/07/08', '2004/01/01'

    Listing 3.13: Executing the user_GetCustomerShipDates stored procedure, with the shorter date range query first.

    As expected, the execution plan has changed dramatically, as shown in Figure 3.7. The smaller number of estimated rows leads the optimizer to use an index seek on our IDX_ShipDate_ASC index, followed by a key lookup to retrieve the remaining rows.

    ***************************************************************************************
    * Figure 3.7: New execution plans for the user_GetCustomerShipDates stored procedure. *
    ***************************************************************************************

    Run Listing 3.13 again, this time without the execution plan but with the statistics, and you'll see that the plan works just fine for the first execution, but causes problems for the next one.

    ==FIRST EXECUTION (SMALL DATE RANGE)===

    Table 'SalesOrderHeader'. Scan count 1, logical reads 127, physical reads 0, readahead reads 0, lob logical reads 0, lob physical reads 0, lob read-ahead reads 0.
    
    SQL Server Execution Times:
    CPU time = 0 ms, elapsed time = 0 ms.

    ==SECOND EXECUTION (LARGE DATE RANGE)===

    Table 'SalesOrderHeader'. Scan count 1, logical reads 52429, physical reads 0.
    
    SQL Server Execution Times:
    CPU time = 47 ms, elapsed time = 182 ms.100
    
    Now that's not a huge jump in CPU time, but remember that even the second execution is dealing with 17,000 rows in the result set. At larger row counts, this problem can have a very significant impact.

    This is a classic, though small-scale, example of parameter sniffing working against us. The plan with the key lookups is only optimal for small row counts (typically < 1% of the table). Above that, the additional I/O and additional CPU required for the key lookups becomes very significant.

    There are several different ways to tackle parameter sniffing problems, depending on the situation and on the version of SQL Server you're using.

    Trace Flag 4136

    SQL Server 2008 introduced an option to turn parameter sniffing off altogether for a SQL Server instance, by simply enabling Trace Flag 4136. This option was added in SQL Server 2008 SP1 CU7, and SQL Server 2008 R2 CU2, and also back-ported into SQL Server 2005 in SP3 CU9.

    When the query optimizer is able to "sniff" the value of a parameter, it uses this value, along with the statistics histogram, to provide an accurate estimate of the number of records that will be returned. As discussed earlier, this is only problematic if the initial parameter value turns out to be completely atypical.

    When parameter sniffing is prevented, the optimizer can't find out the parameter value and so can't use the statistics histogram. Instead, it makes what is often a less accurate estimation of the number of rows that will be returned, by assuming a uniform data distribution across all data values. For example, consider a column X, containing 10 rows with values 1, 2, 3, 3, 3, 3, 3, 4, 5, 5. The optimizer would always estimate that a "WHERE X=value" query will return 2 rows (total number of rows divided by number of distinct values), and so the plan would always be optimized for this number of rows.

    In short, although this option is available, parameter sniffing is beneficial to most procedures that are written to use typical values. Turning parameter sniffing off may inadvertently affect these plans in a negative way. As such, this Trace Flag should be considered an absolute last resort if nothing else fixes the problem.

    Using the OPTIMIZE FOR hint

    In SQL Server 2005 and later, we can use the OPTIMIZE FOR hint to specify a parameter value for the optimizer to use when compiling a plan, as shown in Listing 3.14.

    CREATE PROCEDURE user_GetCustomerShipDates
        (
          @ShipDateStart DATETIME ,
          @ShipDateEnd DATETIME
        )
    AS
        SELECT  CustomerID ,
                SalesOrderNumber
        FROM    Sales.SalesOrderHeader
        WHERE   ShipDate BETWEEN @ShipDateStart AND @ShipDateEnd
        OPTION  ( OPTIMIZE FOR ( @ShipDateStart = '2001/07/08',
                                  @ShipDateEnd = '2004/01/01' ) )
    GO

    Listing 3.14: Using the OPTIMIZE FOR query hint.

    This allows the optimizer to optimize the plan for a parameter value that is known to be more typically used. This will remove the possibility for parameter sniffing, but at the same time may still lead to a plan that is not as efficient, if atypical values are used.

    In SQL Server 2008, this was "extended" to provide the OPTIMIZE FOR UNKNOWN hint, which instructs SQL Server to not use parameter sniffing at all. This allows for a queryby-query control of parameter sniffing, whereas the aforementioned Trace Flag controls the setting for the entire instance. In most cases, the hint is a more desirable solution as, in general, parameter sniffing is a good thing.

    Recompilation options

    We can use the WITH RECOMPILE option, when creating a stored procedure, as another possible solution to parameter sniffing issues. This will mean a plan is never cached for the procedures, since it forces a recompile, and generation of a new plan on every execution. This means that row estimations will always be based on the current parameter value, but at the cost of increasing the execution time of the procedure.

    CREATE PROCEDURE user_GetCustomerShipDates
       (
          @ShipDateStart DATETIME ,
          @ShipDateEnd DATETIME
       )
       WITH RECOMPILE
    AS
       SELECT  CustomerID ,
               SalesOrderNumber
       FROM    Sales.SalesOrderHeader
       WHERE   ShipDate BETWEEN @ShipDateStart AND @ShipDateEnd
    GO

    Listing 3.15: Using the WITH RECOMPILE option.

    The OPTION(RECOMPILE) query hint can be used in much the same way, and may be a better option if there are multiple queries within the procedure and only a portion of them suffer from parameter sniffing problems.

    CREATE PROCEDURE user_GetCustomerShipDates
       (
          @ShipDateStart DATETIME ,
          @ShipDateEnd DATETIME
       )
    AS
       SELECT  CustomerID ,
               SalesOrderNumber
       FROM    Sales.SalesOrderHeader
       WHERE   ShipDate BETWEEN @ShipDateStart AND @ShipDateEnd
       OPTION  ( RECOMPILE )
    GO

    Listing 3.16: Using the OPTION(RECOMPILE) query hint.

    Essas técnicas são úteis quando o custo adicional das compilações é pequeno em comparação com a degradação de desempenho causada pelo reuso de planos inadequados. A dica OPTION(RECOMPILE) deve ser usada sempre que possível, em preferência ao WITH RECOMPILE para um procedimento armazenado, a fim de manter o impacto do processo de compilação repetida o mais baixo possível.

    Ad hoc non-parameterized queries

    Ad hoc queries are statements sent to the optimizer that are not predefined by using stored procedures, sp_executesql or other ways to force reuse of execution plans. The SQL Server will always check on the plan cache to see if a suitable plan can be reused for a given query, before going through the full process of generating a new execution plan and storing it in cache.
    Ad hoc queries will cause execution plans to be generated for each and every statement. This causes excessive use of resources, especially CPU. Consider the three queries shown in Listing 3.17.

    <pre>
        <code>
SELECT  soh.SalesOrderNumber ,
        sod.ProductID
FROM    Sales.SalesOrderHeader AS soh
        INNER JOIN Sales.SalesOrderDetail AS sod
               ON soh.SalesOrderID = sod.SalesOrderID
WHERE   soh.SalesOrderNumber = 'SO43662'
SELECT  soh.SalesOrderNumber ,
        sod.ProductID
FROM    Sales.SalesOrderHeader AS soh
        INNER JOIN Sales.SalesOrderDetail AS sod
               ON soh.SalesOrderID = sod.SalesOrderID
WHERE   soh.SalesOrderNumber = 'SO58928'
SELECT soh.SalesOrderNumber ,
       sod.ProductID
FROM   Sales.SalesOrderHeader AS soh104
       INNER JOIN Sales.SalesOrderDetail AS sod
              ON soh.SalesOrderID = sod.SalesOrderID
WHERE  soh.SalesOrderNumber = 'SO70907'
        </code>
    </pre>
    
    Listing 3.17: Three simple but non-parameterized queries.

    These three statements should produce the same execution plan, but they don't. The different values hard-coded into value assignment in the WHERE clause mean that they are considered by the optimizer to be three different queries, and hence get separate execution plans.

    For very simple queries, SQL Server can use a technique called simple parameterization to replace the fixed values with parameters, and so allow for plan reuse. However, even the queries in Listing 3.17 are too complex to qualify for simple parameterization.

    The problem with non-parameterized queries is two-fold:

    1. The plan cache fills up with lots of single-use plans from ad hoc queries. This means that the memory is used less efficiently. It also means that plans that might have been reusable can get discarded from cache due to memory pressure, requiring them to be compiled again when the queries are rerun.

    2. The compilation of these single-use plans wastes CPU. Compilation is expensive, using relatively large amounts of CPU, and the repeated compilation of plans for ad hoc queries, which are unlikely to be reused, is just a waste of resources.

    Cases where a lack of parameterization is causing excessive plan compilation, or where simple (or forced) parameterization is attempted but fails, can be identified using the following counters from the SQL Statistics objects in Performance Monitor:

    •	 SQLServer: SQL Statistics: SQL Compilations/Sec
    •	 SQLServer: SQL Statistics: Auto-Param Attempts/Sec
    •	 SQLServer: SQL Statistics: Failed Auto-Param/Sec

    Reference: http://msdn.microsoft.com/en-us/library/ms190911(SQL.100).aspx.

    If the non-parameterized ad hoc queries are causing a problem, there are a couple of options for fixing it. The first and best option is to fix the problem at source, in the calling application. If that is not an option, there are settings in SQL Server that can be changed to alleviate the problem.

    Fixing the application

    If it is possible to change the application that is sending these non-parameterized queries to SQL Server, then that option should be the one chosen. This can involve moving data access from ad hoc queries embedded in the front-end code into stored procedures, or it may just involve changing the ad hoc queries that are embedded in the front-end code to their parameterized versions. Listing 3.18 shows an unparameterized query being sent to SQL Server.

    cmd.CommandType = CommandType.Text;
    cmd.CommandText = @"SELECT soh.SalesOrderNumber,
                                sod.ProductID
                        FROM   Sales.SalesOrderHeader AS soh
                                  INNER JOIN Sales.SalesOrderDetail AS sod
                                         ON soh.SalesOrderID = sod.SalesOrderID
                        WHERE  soh.SalesOrderNumber = '" + txtSalesOrderNo.Text + "'";

    dtrSalesOrders = cmd.ExecuteReader();

    Listing 3.18: An unparameterized query being sent to SQL Server.

    Listing 3.19 shows the same query, but now in a parameterized form that will allow plan reuse.
    
    dtrSalesOrders.Close();
    cmd.CommandType = CommandType.Text;
    cmd.CommandText = @"SELECT soh.SalesOrderNumber,
                                sod.ProductID
                        FROM   Sales.SalesOrderHeader AS soh
                                  INNER JOIN Sales.SalesOrderDetail AS sod
                                         ON soh.SalesOrderID = sod.SalesOrderID
                        WHERE  soh.SalesOrderNumber = @SalesOrderNo";

    cmd.Parameters.Add("@SalesOrderNo", SqlDbType.NVarChar, 50);
    cmd.Parameters["@SalesOrderNo"].Value = txtSalesOrderNo.Text;

    dtrSalesOrders = cmd.ExecuteReader();

    Listing 3.19: A parameterized query being sent to SQL Server.
    
    If changing the application is not possible, as is often the case with vendor applications, or where the source code for the application is unavailable, then there are two options in SQL Server that can help alleviate the problem: forced parameterization and optimize for ad hoc workloads.
    
    Forced parameterization in SQL Server
    
    SQL Server 2005 and above offers the ability to set the database-level PARAMETERIZATION option to FORCED, using the ALTER DATABASE statement, as shown in Listing 3.20. This will force all ad hoc queries against that database to be parameterized before the compile process starts.

    ALTER DATABASE AdventureWorks SET PARAMETERIZATION FORCED

    Listing 3.20: Setting the PARAMETERIZATION option to FORCED.

    If you run this command and then rerun the three queries from Listing 3.17, the query that the SQL Query Optimizer gets to optimize will be the parameterized version, and you'll find that there's only one plan created in cache, not three.

    There are potential downsides to using forced parameterization, in that this setting forces SQL to use one plan for all matching queries, no matter what the literal values, so there is a possibility for the same parameter sniffing problems to which stored procedures are susceptible. If such a problem does occur, it can be investigated and resolved in much the same way as with stored procedures, discussed earlier in this chapter.

    Optimize for ad hoc workloads

    In SQL Server 2008 and later, we can use optimize for ad hoc workloads, which is a server-level setting, i.e. it will affect every single database on the server (as opposed to forced parameterization, which is database-specific).

    With this setting enabled, SQL Server does not cache the plan of an ad hoc query the first time it is encountered. Instead, a plan-stub is cached that just indicates that the query has been seen before. Only if the query is seen a second time is the plan cached. This won't reduce the number of compiles for ad hoc queries, but it will make it less likely that the plan cache will grow as much, since the initial stub takes up very little memory. As such, it reduces the chances that other plans which could be reusable will be discarded due to memory pressure.

    To enable the optimize for ad hoc workloads setting, use sp_configure, as shown in Listing 3.21.
    
    EXEC sp_configure 'show advanced options',1
    RECONFIGURE
    EXEC sp_configure 'optimize for ad hoc workloads',1
    RECONFIGURE
    
    Listing 3.21: Enabling the optimize for ad hoc workloads setting.
    
    Inappropriate parallelism

    SQL Server is designed to be able to make use of multiple processors when processing user requests. Query parallelism is the mechanism used by the SQL query execution engine to split the work of a query into multiple threads, each of which will execute on a separate scheduler. Queries are parallelized at the operator level; in other words, if the query runs in parallel, some of the query operators may run in their parallel form, while others may not.
    
    ******************************************************************************
    * Figure 3.8: Execution plan showing that operators are running in parallel. *
    ******************************************************************************

    When a query is submitted to SQL Server for processing, the query optimizer compiles an execution plan that has been optimized to allow the query to execute in the fastest manner possible. If the estimated cost of executing the plan serially exceeds the 'cost threshold for parallelism' sp_configure option, the number of logical CPUs available to SQL Server is greater than one, and the 'max degree of parallelism' sp_configure option is set to the default of zero or greater than one, the plan produced will include parallelism. The Degree of Parallelism (DOP) is not included as a part of the plan; this is, instead, determined at the time of execution based on the number of logical processors, the 'max degree of parallelism' sp_configure or, if the MAXDOP query hint is being used, the value specified by the hint, and the number of available worker threads.

    Parallel query processing can reduce the time required to process a query by horizontally partitioning the input data, distributing the partitions across multiple logical CPUs, and simultaneously executing the same operation across multiple processor cores. This can be very beneficial to data warehouse and reporting operations, which have a few large queries that deal with volumes of data and only a few requests occur concurrently. By splitting the request across multiple OS threads on multiple processor cores, the optimizer increases the utilization of the hardware resources by spreading the load across all of the processors on the server, resulting in a reduction of total execution time.

    The specific impact of a parallel workload depends on a number of factors, not the least of which is the ability of the remaining hardware components in the system to cope with the heavy demands for memory allocation and disk I/O that a parallel workload can generate. When parallelism is used appropriately, on high-cost queries, it can have a very beneficial effect on overall server performance. However, it can be very detrimental to OLTP environments where the workload consists of lots of smaller queries executing concurrently, since the parallel operation can utilize up to all of the processor cores on the server, causing other requests to wait to execute. If the primary use of the server is for an OLTP database that has a lot of smaller concurrent requests, parallelism of a single common query can sink throughput.

    As noted above, SQL Server has two configuration options that control the parallel execution of queries by the engine. They are the cost threshold for parallelism and the max degree of parallelism options of sp_configure. The max degree of parallelism option exists to prevent a single query from utilizing all of the processor cores on a SQL Server. The cost threshold for parallelism option exists to control the threshold for a query that causes the optimizer to use parallelism to execute a query.

    Too often, when CPU issues related to "inappropriate parallelism" arise, the suggested solution seems to focus solely on changing the value for max degree of parallelism. For example, a quick online search of the problem, especially the CXPACKET wait type (a classic indicator of parallelism-related issues, as discussed a little later) will result in numerous posts that recommend reducing the max degree of parallelism to one half or one fourth the number of logical processors or processor cores on the server, or even to completely disable parallelism by setting it to 1. While this may solve the problem, it may not be the ideal solution. The best solution is to consider, in tandem, the appropriate value for each of these options.

    Cost threshold for parallelism

    As discussed, the cost threshold for parallelism option determines a threshold "cost" which, when exceeded, will cause a parallel execution plan to be generated, in order to execute the user request. Since parallel execution is only possible on multi-processor systems, the cost threshold for parallelism option is only used by the engine when multiple processors exist, the server is not affinitized to a single processor and max degree of parallelism is set to a value other than I.

    The "cost" is the estimated amount of time in seconds that it would take to execute the query serially with a given execution plan. The default value is five, meaning that a parallel plan will only be generated and used by queries that are estimated to take longer than five seconds to execute serially on the given system. On larger databases, this threshold may be low enough to cause multiple concurrent executions of common queries, and so to cause contention in the system.

    To determine what might be an appropriate setting for the cost threshold for parallelism option, it is possible to query the existing plans in the plan cache to determine the costs associated with the plans that have been executing with parallelism, as shown in Listing 3.22.

    SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED ;

    WITH XMLNAMESPACES
       (DEFAULT 'http://schemas.microsoft.com/sqlserver/2004/07/showplan')
    SELECT query_plan AS CompleteQueryPlan ,
           n.value('(@StatementText)[1]', 'VARCHAR(4000)') AS StatementText ,
           n.value('(@StatementOptmLevel)[1]', 'VARCHAR(25)')
                     AS StatementOptimizationLevel ,
           n.value('(@StatementSubTreeCost)[1]', 'VARCHAR(128)')
                     AS StatementSubTreeCost ,
           n.query('.') AS ParallelSubTreeXML ,
           ecp.usecounts ,
           ecp.size_in_bytes
    FROM   sys.dm_exec_cached_plans AS ecp
           CROSS APPLY sys.dm_exec_query_plan(plan_handle) AS eqp
           CROSS APPLY query_plan.nodes
                  ('/ShowPlanXML/BatchSequence/Batch/Statements/StmtSimple')
           AS qn ( n )
    WHERE n.query('.').exist('//RelOp[@PhysicalOp="Parallelism"]') = 1

    Listing 3.22: Determining the estimated cost of parallel execution plans.

    Analysis of the most commonly executed statements that result in parallel queries can guide the appropriate setting of the cost threshold for parallelism option to minimize the impact of multiple concurrently executing parallel requests which drive CPU and I/O contention in the system.

    Max degree of parallelism

    Whenever the estimated cost of executing a query serially exceeds our carefully-evaluated value for cost threshold for parallelism, the database engine can spread the execution load for that query across multiple available processors, according to the degree of parallelism dictated by the max degree of parallelism option. The number of processors used will be determined by the lowest of the following three values:

    •	 number of available processors
    •	 max degree of parallelism option
    •	 MAXDOP query hint provided for the query being executed (which overrides the value specified by max degree of parallelism).

    Generally speaking, as we have discussed, the appropriate value for the max degree of parallelism option depends largely on the type of workload being executed, and the ability of the other hardware subsystems to cope with the additional workload associated with parallel execution in the system. If your system is experiencing parallelism-related issues (see the Diagnosing inappropriate parallelism section), then it may be necessary to limit the degree of parallelism, in conjunction with tuning the cost threshold for parallelism to resolve the problem.

    One of the more common online recommendations is to disable parallelism entirely by setting the max degree of parallelism to 1. There are cases where this configuration might make sense, for example, true OLTP workloads where all of the transactions are small and there are a lot of transactions executing concurrently. These types of database rarely exist today and disabling parallelism entirely is more likely to reduce performance in the long term.

    Over the years I've made a number of different recommendations about how to configure max degree of parallelism. For example, in a SMP system, setting it to half the number of available physical processor cores, or to the number of physical cores on a single processor die, or even setting it to 1 to disable parallelism entirely. Today, I only make a recommendation based on analysis of the query workload, and a review of the wait types of associated workers and subtasks which are executing using parallelism.

    In particular, I'll analyze occurrences of the CXPACKET session wait type. In most systems, CXPACKET is the symptom and not the problem; there is often a different underlying wait type that can be seen in sys.dm_os_waiting_tasks for the session. By focusing on this wait type, a better decision regarding the appropriate max degree of parallelism option can be made. For example, if the underlying wait type, is PAGEIOLATCH_SH then the parallel operation is waiting on a read from the disk I/O subsystem, and reducing the max degree of parallelism won't resolve the root problem; it will just reduce the number of workers being used in the system, and reduce the accumulated wait time for the CXPACKET wait type. However, this may reduce the additional load the parallelism operations place on the disk I/O subsystem, and buy you time to scale up the I/O performance of the server.

    There are, however, some specific considerations, relating to the memory architecture of the processors. On NUMA-based (Non-Uniform Memory Access) systems, the max degree of parallelism option should be set to the minimum number of processors available on a single NUMA node. This is done to prevent cross-node parallel processing of a request from occurring, which incurs significant expense since sharing memory across nodes is an expensive operation.

    On Symmetric Multiprocessing (SMP) systems, one of the trade-offs with multiple processor cores on a single die is the usage of shared L2 caches across multiple cores, which can result in cache misses for memory-consuming applications such as SQL Server, and which affects the performance of highly concurrent workloads, under higher levels of parallelism. Here, the appropriate value for this option depends largely on the type of workload being executed and the ability of the other hardware subsystems to cope with the added workload associated with parallel execution in the system.

    Finally, note that on SQL Server 2008 and above, the resource governor can be used to enforce a max degree of parallelism for groups of queries, based on various connection properties. Hence it would be possible to limit queries from one application, a specific set of logins or specific hostnames, to a certain max degree of parallelism and let other queries be unlimited.

    Hyper-threading and parallelism

    Hyper-threading is an Intel technology designed to improve parallel execution by presenting to the operating system two logical cores for each physical core. This means that instead of one scheduler per processor core you get two, and so two threads can be executed "simultaneously."

    AMD processors and two strong threads

    Modern AMD processor architectures, such as Bulldozer, use a different approach to threading, called two strong threads, with a design that offers dedicated hardware to each of two threads. We won't discuss this topic further here, but further information can be found on the AMD website: http://www.anandtech.com/show/3863/amd-discloses-bobcat-bulldozer-architectures-at-hot-chips-2010.

    A question that is commonly asked in the online forums is whether or not hyperthreading should be enabled for SQL Server, and how such decisions are affected by workload type.

    As discussed earlier, for an OLAP or DSS workload, query execution performance will benefit from allowing the query optimizer to parallelize individual queries. This is certainly true when there exist a large number of true, physical CPU cores but, on early hyper-threading implementations, it was the experience of most DBAs that the often complex queries that comprised a typical OLP/DSS workload performed poorly when parallelized across multiple hyper-threaded cores. A typical, short OLTP query was less affected by running on a logical core, as opposed to a physical one, so enabling hyperthreading for an OLTP workload could see a benefit from parallelization in the sense that more cores were available to process more queries in a given time.

    Nevertheless, several architectural problems with early hyper-threading implementations, which became more and more problematical as the CPU load on a server increased, meant that most DBAs simply disabled hyper-threading in the BIOS, regardless of workload type.

    As recently as a few years ago, when SQL Server 2008 RTM first released, advice to disable hyper-threading for SQL Server, especially for DW/OLAP/DSS workloads, was generally correct. The biggest problem with older processors and hyper-threading related to the size of the onboard caches, which are shared when hyper-threading is enabled. The smaller cache size meant that cache misses were common place for memory-dependent applications like SQL Server. Another issue early on was that Windows Server 2000 wasn't hyper-threading aware so, when you had a dual processor server with hyperthreading enabled, Windows thought it had four physical processors, and would schedule concurrent execution on both threads of a processor when under load.

    However, recent advances and improvements in hardware and in Windows, as well as in hyper-threading implementation mean that it is simply incorrect to disable hyperthreading as a matter of course. Many of the early problems no longer exist. For example, Windows Server 2003 and later are hyper-threading aware and so will see two physical and two logical processors, and will handle scheduling differently to accommodate the fact that two of the logical processors are from hyper-threading. Also, newer processors have much larger caches (MB instead of KB); they are less prone to the cache-miss issues and are much better suited for using hyper-threading with memory dependent implementations like SQL Server, especially on Windows Server 2008.

    In fact, with recent processor architectures, especially Intel Nehalem and later, my advice is to enable hyper-threading unless you find a good reason to turn it off. It's certainly a mistake to disable hyper-threading without first thoroughly testing your application workload with hyper-threading enabled, then disabled, in order to truly know whether or not there is a benefit to having hyper-threading turned on or off.

    Of course, as processors with eight or even twelve physical cores emerge onto the market, it becomes easier to achieve high levels of parallelism without the need for hyperthreading. However, the technology remains fundamental to Intel's modern processors (for example, the Xeon E7-4870 processor, for 4-socket servers, boasts ten physical core plus hyper-threading), and with most recent processor architectures, there is a good chance that you'll see a performance and/or throughput benefit for both DW/OLAP and OLTP workloads.

    Diagnosing inappropriate parallelism

    The best way to determine if parallel processing is causing a resource bottleneck in a specific system is to look at the wait statistics and latch statistics for an instance of SQL Server. When a bottleneck exists during the parallel execution of a query, the CXPACKET wait type shows up as one of the top waits for SQL Server. This wait type is set whenever a parallel process has to wait in the exchange iterator for another worker to continue processing. As previously discussed, when this happens, there is generally an underlying, non-CXPACKET wait type, which is associated with the stalled worker. However, since multiple workers are forced to wait when this occurs, the volume of CXPACKET waits will generally exceed the underlying root wait type being exhibited.

    Whenever possible, it is best to isolate and troubleshoot the underlying wait type, since this will lead to overall system throughput improvements. The CXPACKET waits are simply a symptom of a problem in most cases, not the actual problem. There are scenarios where it may not be possible to eliminate the underlying wait type; for example, when the disk I/O subsystem can't keep up with the demand required by the parallel execution of a query, the root wait type may be an IO_COMPLETION, ASYNC_IO_COMPLETION, or PAGEIOLATCH_* wait type, and scaling out the I/O subsystem is not possible. When this occurs, reducing the level of parallelism to a degree that still allows parallel processing to occur without bottlenecking in the disk I/O subsystem can improve overall system performance. It is possible that CXPACKET waits in conjunction with other wait types, for example LATCH_* and SOS_SCHEDULER_YIELD, do show that parallelism is the actual problem, and further investigation of the latch stats on the system will validate if this is actually the case. The sys.dm_os_latch_stats DMV contains information about the specific latch waits that have occurred in the instance, and if one of the top latch waits is ACCESS_METHODS_DATASET_PARENT, in conjunction with CXPACKET, LATCH_*, and SOS_SCHEDULER_YIELD wait types as the top waits, the level of parallelism on the system is the cause of bottlenecking during query execution, and reducing the 'max degree of parallelism' sp_configure option may be required to resolve the problems.

    Resolving parallelism issues

    As discussed earlier, larger, long running queries will generally benefit from parallel execution, since the cost of executing the query serially outweighs the cost associated with initialization, synchronization and termination of the parallel workers, for parallel execution of the query. Inappropriate parallelism most commonly arises in cases where the nature of the workload is "mixed," i.e. we have what is essentially an OLTP workload, characterized by a large number of short transactions, but where some of those transactions are actually complex enough that the cost threshold for parallelism is exceeded and SQL Server parallelizes their execution across all available cores, so tying up CPU resources.

    When parallelism-related issues are diagnosed, the first possible remedy that should be investigated is optimizing the queries that are parallelizing inappropriately, if they are not already tuned. Inappropriate parallelism can easily be a result of missing/inadequate indexes, outdated statistics or badly written queries. In other words, by tuning these queries, they'll cease to exceed the cost threshold for parallelism, and so will naturally execute on a single CPU core.

    If the workload is as tuned as it can be, and parallelism issues persist, then the cost threshold for parallelism option should be used in conjunction with the max degree of parallelism option to manage parallel execution in the system overall.

    TokenAndPermUserStore

    The TokenAndPermUserStore cache was introduced in SQL 2005 as an optimization that would allow caching of the results of permissions checks by users against database objects. This cache, however, could be the cause of performance problems, especially in earlier builds of SQL Server 2005, because the limits on the size of the cache were too high. The performance problems typically manifested as excessively high CPU usage and threads with high CMEMTHREAD waits. This section will cover how to identify problems associated with the TokenAndPermUserStore cache, short-term work-arounds, hot fixes from Microsoft for the problem, as well as how to solve the problem in the long term.

    The problem is discussed in the Knowledge Base article 927396 (http://support.microsoft.com/kb/927396) and tends to materialize under the following circumstances:

    •	 large amounts of non-AWE memory allocated to SQL Server (this means the problem is specific to 64-bit SQL)
    •	 lots of dynamic or ad hoc SQL queries
    •	 many different database users.

    To investigate possible problems related to the TokenAndPermUserStore cache, track the size of the cache over a period of time, using the query shown in Listing 3.23.

    SELECT SUM(single_pages_kb + multi_pages_kb) / 1024.0 AS CacheSizeMB
    FROM sys.dm_os_memory_clerks
    WHERE [name] = 'TokenAndPermUserStore'

    Listing 3.23: Finding the size of the TokenAndPermUserStore cache.

    If the cache constantly grows in size, and that growth is accompanied by queries waiting with a CMEMTHREAD wait type, then the size of the cache may be the cause of the high CPU usage.

    If you're using a SQL Server 2005 and the patch level is below SP2, the first thing to do is apply SP2 at the very least, and preferably SP4, since improvements in the management of this cache were made in SP2.

    A best long-term fix, however, is an architectural change to reduce the usage of ad hoc or dynamic SQL, and move as much logic as possible into stored procedures. Depending on the application architecture this may be anything from trivial to impossible, but it should be considered, as doing so almost completely removes the chance of running into this problem.

    Short-term fixes in SQL Server 2005

    If these measures aren't immediately possible, there are a couple of short-term work-arounds to this problem in SQL Server 2005.
    
    Use the sysadmin server role

    By making the application service account a member of the sysadmin server role, any permissions checking is bypassed and the problem is resolved. The assumption is that the account can perform any operation inside of SQL Server and therefore does not require additional permissions checks.

    This solution is very far from ideal, since it provides elevated permissions to the service account. In a pinch, it will provide short-term relief to the problems associated with high CPU utilization. However, if it works, proving that the TokenAndPermUserStore cache is the root cause, then you should immediately determine if another solution can be utilized instead, to solve the problem.

    Regularly clear the cache

    Using a SQL agent job and the command shown in Listing 3.24, you can regularly free up space in the TokenAndPermUserStore cache.
    
    DBCC FREESYSTEMCACHE ('TokenAndPermUserStore')
    
    Listing 3.24: Freeing space in the TokenAndPermUserStore cache.
    
    Again, this should only is done in extreme cases and as a temporary solution. However, it will control the cache size until a long-term resolution can be applied.

    Trace Flags

    On SQL 2005 SP2 or above, Trace Flag 4618 and/or Trace Flag 4610 can be enabled. Trace Flag 4618 restricts the number of entries that the cache will hold to 1024 and, if both flags are enabled, the number of cache entries is limited to 8192. Restricting the number of entries the cache will hold should be used temporarily, while other fixes are taken into consideration.

    One last configuration change option on SQL 2005, if on SP3 or above, is that Trace Flag 4621 can be enabled. This allows a custom quota to be set. For the details of configuring this, see Knowledge Base article 959823 (http://support.microsoft.com/kb/959823).

    Configuration options in SQL Server 2008

    With SQL Server 2008, the configuration options access check cache bucket count and access check cache quota were introduced. These options control the number of entries and number of hash buckets used for the TokenAndPermUserStore cache. The cache should not cause the same problems on SQL 2008 as it did on SQL 2005, but if the problems do manifest, the quota can be set to a lower number and/or the number of hash buckets can be increased. Changing these settings can reduce the time necessary to locate cache entries. This configuration change is, however, not a recommended change unless directed under the guidance of Microsoft Customer Support, but IT should be noted as an area for your troubleshooting.

    Windows Server and BIOS power saving options

    As a part of the green computing initiatives, many hardware manufacturers ship new desktops, laptops, and even servers intended for datacenter use, with the advanced power control configuration set such that the operating system, or the hardware itself, can automatically reduce power consumption and cooling requirements of the system by turning off devices that are not being used, and under-clocking the processors installed in the server. Unfortunately, this can have quite a negative impact on your processor performance.

    These hardware-based power-saving settings can be configured in the main system BIOS to allow the hardware to control power consumption (Hardware), the Windows operating system to control power management (OS Control), or to disable power management features completely (None). In general, the default option for the BIOS is to allow the operating system to control the power management features of the system, based on its configured options.

    Windows Server 2008 and 2008 R2 default the power management configuration setting (the Windows Power Plan feature) to Balanced, which allows the system to switch to a low performance state to reduce power consumption. One of the surprises that many people have had, on upgrading their systems on newer server hardware that has Windows Server 2008 or 2008 R2 installed on it, is that overall performance decreases after a period of time and ends up being significantly lower than when the server first started up. This is a direct result of power management features causing under-clocking of the processors on the server.

    To identify if this is a problem on your system, a free tool named CPU-Z, available from http://www.cpuid.com/softwares/cpu-z/versions-history.html, can be used to collect information about the current state of the processors installed in a server. We won't discuss this tool in detail here, but the important values to look out for, in regard power management problems, are the CPU Specification, which will show the type of processor and its rated clock speed, and the Core Speed, which shows the current clock speed of the processors in the system. If the Core Speed is lower that the rated specification, then power management is reducing the performance of the system.

    The first thing to do is to check the current Windows power management scheme. If it is set to Balanced, change it to High Performance, which prevents the system from switching to a low performance state and ensures the performance characteristics of the system are consistent (see http://support.microsoft.com/kb/2207548). If High Performance is being used by Windows, the BIOS setting should be checked. If it's set to Hardware, change it to OS Control.

    What is insidious here is the impact that power saving has on the % Processor Usage performance counter. The value for this counter is calculated based on the currently used CPU frequency, divided by the available CPU frequency. As such, an under-clocked CPU causes Windows to report higher CPU usage values, leading people to believe that the server is under heavier load than it is in reality.

    Summary

    Poor management of CPU utilization can and will often have a dramatic impact on SQL Server performance. In general the sustained CPU usage of a SQL Server machine should not exceed 60–70%. Occasional spikes to higher values should not be a problem, but sustained heavier usage is an indication that the server is under severe CPU load.

    When CPU issues arise, and having confirmed that the high CPU usage is due to the SQL Server process, the first job is to isolate the source of the problem, using information from tools such as Performance Monitor (PerfMon), SQLTrace and the SQL Server Dynamic Management Views, many of which have been greatly enhanced with the releases of SQL Server 2005 and 2008.

    With the problem located, the appropriate measures can be taken to relieve the CPU pressure, ranging from adding useful indexes and tuning CPU-hungry queries, to changing configuration settings. If all of this fails, it may simply be that you need more or faster CPUs along with a better balancing of the load across CPUs, and better scheduling of CPU-intensive queries.

    Additional Resources

    •	 Implicit data conversations
    •	 http://sqlblog.com/blogs/jonathan_kehayias/archive/2010/01/08/findingimplicit-column-conversions-in-the-plan-cache.aspx
    •	 Query tuning
    •	 http://www.straightpathsql.com/presentations/ucandoit/
    •	 http://www.simple-talk.com/sql/performance/simple-query-tuning-with-statistics-io-and-execution-plans/
    •	 http://www.simple-talk.com/sql/t-sql-programming/13-things-youshould-know-about-statistics-and-the-query-optimizer/
    •	 http://www.simple-talk.com/author/gail-shaw/
    •	 Estimated vs. actual row counts
    •	 http://sqlinthewild.co.za/index.php/2009/09/22/estimated-rows-actual-rows-and-execution-count/
    •	 Cost threshold for parallelism
    •	 http://sqlblog.com/blogs/jonathan_kehayias/archive/2010/01/26/21172.aspx
    •	 Max degree of parallelism
    •	 http://msdn.microsoft.com/en-us/library/ms181007.aspx
    •	 Query hints
    •	 http://msdn.microsoft.com/en-us/library/ms181714.aspx
    •	 Guidelines for modifying MAXDOP
    •	 http://support.microsoft.com/kb/329204
    •	 Limiting MAXDOP with the Resource Governor
    •	 http://www.sqlmag.com/blog/sql-server-questions-answered-28/database-administration/controlling-maxdop-executing-queries-140163
    •	 Parallelism/MAXDOP configuration
    •	 http://msdn.microsoft.com/en-us/library/ms178065.aspx
    •	 http://msdn.microsoft.com/en-us/library/ms188611.aspx
    •	 http://blogs.msdn.com/b/joesack/archive/2009/03/18/should-you-worryabout-sos-scheduler-yield.aspx
    •	 SQLOS architecture
    •	 http://blogs.msdn.com/b/sqlosteam/archive/2010/06/23/sqlos-resources.aspx
    •	 http://sqlblogcasts.com/blogs/sqlworkshops/archive/2007/11/25/findingoptimal-number-of-cpus-for-a-given-long-running-cpu-intensive-dss-olaplike-queries-workload.aspx
    •	 System Monitor CPU counters
    •	 http://msdn.microsoft.com/en-us/library/ms178072.aspx
    •	 DMV usage for CPU usage from ring buffers
    •	 http://troubleshootingsql.com/2009/12/30/how-to-find-out-the-cpuusage-information-for-the-sql-server-process-using-ring-buffers/
    •	 http://msdn.microsoft.com/en-us/library/ms175048(SQL.90).aspx
    •	 http://technet.microsoft.com/en-us/library/cc966540.aspx
    •	 Forced parameterization
    •	 http://technet.microsoft.com/en-us/library/ms175037(SQL.90).aspx
    •	 Fixing TokenAndPermUserStore problems
    •	 Identification and overview
    •	 http://support.microsoft.com/kb/927396
    •	 Access check result cache
    •	 http://support.microsoft.com/kb/955644
    •	 http://msdn.microsoft.com/en-us/library/cc645588.aspx
    •	 Purging the cache whenever it reaches a certain size
    •	 http://blogs.msdn.com/chrissk/archive/2008/06/19/script-to-purgetokenandpermuserstore.aspx
    •	 SQL Server 2008 sp_configure options
    •	 http://support.microsoft.com/kb/955644/en-us
    •	 Hot-fixes associated with this problem
    •	 http://support.microsoft.com/kb/959823126    
</body>
</html>