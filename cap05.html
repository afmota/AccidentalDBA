<!DOCTYPE html>
<html lang="pt-br">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Accidental DBA</title>
</head>
<body>
    Chapter 5: Missing Indexes

    Indexes in SQL Server provide optimized access to data inside of a database, and one of the common causes of performance problems with a SQL Server database is missing or incorrect indexes on tables within the database.

    Great strides have been made in SQL Server 2005 and 2008 to assist in identifying missing indexes, via the use of:

    •	 the Database Engine Tuning Advisor – analyses the execution plans generated for a supplied workload, along with the physical characteristics of the database, and recommends a set of indexes
    •	 the Missing Index feature – provides information regarding potentially useful indexes, stored in Dynamic Management Views and in XML Showplans.

    However, the information provided by these tools, in particular the latter, can cause problems when used incorrectly. We'll cover two of the most critical factors regarding the appropriate structure of the indexes to be created, namely the index key column order and the appropriate use of included columns. This will help you to evaluate and verify the index recommendations made by these tools, in light of your knowledge of the data and workload for the given database.

    Finally, since indexes come with a maintenance cost, we'll discuss how to identify any unnecessary indexes in your database, either duplicate indexes or those that are being maintained but never used by any queries.

    Note that this chapter focuses exclusively on identifying an appropriate set of indexes for a given database; related index issues that could also affect query performance, such as index fragmentation, are not covered.

    Index Selection and Design

    Selecting the appropriate set of indexes for a database requires an understanding of how the database is used, and the data it contains. An indexing strategy that may be applied to a data warehouse or decision support system will be very different from the strategy that would be appropriate for an online transaction processing (OLTP) system. However, in any type of database, the general indexing strategy should be to establish indexes that are not necessarily query specific, but instead provide the best performance for the overall workload against the database.

    In defining an appropriate set of indexes, you will ensure that the most significant queries in your workload are able to read only the minimum required amount of data, and in a logical, ordered fashion, enabling them to return that data quickly and efficiently, with minimal read I/O.

    Conversely, if a database lacks an appropriate set of indexes for the required workload, then any searches against non-indexed columns will be resolved by performing Clustered Index Scans or Table Scans, reading far more data than is necessary to return the required result set, and leading to high associated read I/O costs.

    To understand the overall workload, you have to first know the specific queries that will be executed against the database, and then how frequently each of them will be executed. An index that improves the performance of a single query that is executed once or twice a day may not be worth creating if the query, when it runs, is not impacting the overall performance of the server. If the same query ran a few thousand times an hour, however, the impact of the index would likely be significant enough that creating it would be beneficial.

    Remember that, while indexes can improve the performance of specific queries in SQL Server, they are not free. There is a cost associated with maintaining the records contained in each index, and this cost must be balanced against the performance benefits that each individual index provides. A database that has too many indexes will have a large write I/O cost associated with maintaining the indexes, for every INSERT and DELETE operation, as well as any UPDATE operations that affect an indexed column. Furthermore, as your indexes grow larger and more numerous, so the cost of performing routine maintenance work, such as backups, index reorganization and rebuild, and DBCC CHECKDB operations, will rise accordingly.

    Index key column order

    It is fairly common to find recommendations online that state the index key columns should be ordered based on their cardinality (or selectivity), the idea being to reduce the number of pages that have to be read to match a set of filtering or grouping columns.

    However, selecting the appropriate key column order is never as straightforward as most online content makes it seem, and you won't generally find a lot of guidance about when and why you might choose to create an index that has the columns in an order that is different from the cardinality order. For example, is it better to create multiple indexes, where each individual index has the optimal key column order, based on column selectivity, or to create a single index that covers multiple queries, but has a less selective column order?

    Ultimately, your decision should be based on the type of database for which the index is being implemented. For a data warehouse, where there are significantly more read operations than write operations, the multiple indexes option may be appropriate. For an OLTP system, where there are more writes than reads, a less selective index that covers multiple queries using a less than optimal column order may be most appropriate.

    The most important point to understand though, regarding index key column order, is that a query cannot seek on an index unless the query filters on a left-based subset of the index key. To demonstrate this point, let's say we have the index and queries shown in Listing 5.1.

    CREATE INDEX idx_Test ON TestTable (Col2, Col1, Col3)
    
    SELECT  1
    FROM    TestTable
    WHERE   Col1 = @Var1
            AND Col2 = @Var2
            AND Col3 = @Var3
    
    SELECT  1
    FROM    TestTable
    WHERE   Col1 = @Var1
            AND Col3 = @Var3
    
    SELECT  1
    FROM    TestTable
    WHERE   Col2 = @Var2
            AND Col3 = @Var3

    Listing 5.1: Various queries against a simple three-column index.

    The first query can seek effectively on the index because it filters on all three columns of the index (the order of clauses in the WHERE clause is irrelevant).

    The second query cannot seek on that index; the leading column of the index is Col2 and that query does not filter on Col2. The query can use that index, but only via a scan.

    The third query can seek on the index, but the seek is not as efficient as it could be, as SQL can only seek for Col2; it would have to do a secondary filter for Col3, since Col3 is not the second column in the index.

    If I wanted to create the minimum number of indexes that could allow SQL Server to resolve all three queries as efficiently as possible, i.e. with index seeks, then I could create an index for each query, or I could try several combinations of two indexes, with differing index key ordering. The selectivity of the various columns would help choose which pair were the most appropriate. Some of the options are shown in Listing 5.2.

    --3 possible pairs of indexes

    CREATE INDEX idx_Test1
    ON TestTable (Col1, Col3, Col2)
    CREATE INDEX idx_Test1
    ON TestTable (Col2, Col3)

    --OR—

    CREATE INDEX idx_Test
    ON TestTable (Col2, Col3, Col1)
    CREATE INDEX idx_Test1
    ON TestTable (Col1, Col3)
    
    --OR--
    
    CREATE INDEX idx_Test
    ON TestTable (Col3, Col1, Col2)
    CREATE INDEX idx_Test1
    ON TestTable (Col2, Col3)
    
    Listing 5.2: Three possible pairs of indexes.
    
    Let's look at a quick AdventureWorks example. Listing 5.3 shows three queries, each with a different predicate in the WHERE clause.

    SELECT  BusinessEntityID ,
            PersonType ,
            FirstName ,
            MiddleName ,
            LastName ,
            EmailPromotion
    FROM    Person.Person AS p
    WHERE   FirstName = 'Carol'
            AND PersonType = 'SC'
    
    SELECT  BusinessEntityID ,
            FirstName ,
            LastName
    FROM    Person.Person AS p
    WHERE   PersonType = 'GC'
            AND Title = 'Ms.'
    
    SELECT  BusinessEntityID ,
            PersonType ,
            EmailPromotion
    FROM    Person.Person AS p
    WHERE   Title = 'Mr.'
            AND FirstName = 'Paul'
            AND LastName = 'Shakespear'
    
    Listing 5.3: Three queries against AdventureWorks.

    We could create three indexes, each one perfectly suited to a single query, and in a data warehouse environment that may indeed be the best option. In an OLTP environment where the number of indexes should be kept low, in order to maintain good INSERT performance, it may not be such a good idea.

    In terms of selectivity, the LastName column is the most selective, followed closely by FirstName. The Title and PersonType columns have a much lower selectivity, each having only six distinct values in the table. In this case, we could create just the two indexes shown in Listing 5.4, and have all the queries in Listing 5.3 perform very well.

    CREATE INDEX idx_Person_FirstNameLastNameTitleType
    ON Person.Person (FirstName, LastName, Title, PersonType)

    CREATE INDEX idx_Person_TypeTitle
    ON Person.Person (PersonType, Title)

    Listing 5.4: Two indexes, designed based on column selectivity.

    The first index satisfies the first and third queries. It's not perfect for the first one, but given how selective the FirstName column is, it's likely to be good enough. I've chosen to have FirstName as the leading column despite having slightly worse selectivity than LastName, because if I put LastName as the leading column then the first query would be unable to seek on it and I would need a third index to completely satisfy all queries.

    With the second index, the order of columns is arbitrary. Neither the queries nor the selectivity shows a preferred order, so either way works. In a real environment, the order would probably be decided by other indexes or queries.

    It should be clear even from this relatively simple example that determining the optimal order of columns for an index can be a complex process and is not something that should be decided on without sufficient analysis and investigation.

    More on index selectivity

    SQL Server MVP, and Technical Reviewer for this book, Gail Shaw, discusses this topic in further detail on her two blog posts: "Index columns, selectivity and equality predicates" (http://sqlinthewild.co.za/index.php/2009/01/19/index-columns-selectivity-and-equality-predicates/) and "Index columns, selectivity and inequality predicates" (http://sqlinthewild.co.za/index.php/2009/02/06/index-columns-selectivity-and-inequality-predicates/).

    Use of included columns

    Many of the features described in the remainder of this chapter, for identifying missing indexes in the databases of a SQL Server instance, will make recommendations regarding the use of include columns, so a brief discussion of the benefits and impact of included columns is necessary.

    Included columns, a new feature in SQL Server 2005, allow creation of non-clustered indexes that contain non-key columns as a part of the index definition, so that a single index can cover more queries. The key columns of an index are stored at all levels of the index, but the included columns are only stored at the leaf level of the index. The typical usage for included columns is in creating indexes that cover queries. A covering index is one that contains all of the columns needed by a query, as either key or non-key columns, preventing the need to access the table or clustered index using lookup operations, and so decreasing the number of I/O operations required to return the data.

    Included columns can only be created on non-clustered indexes, and the non-key columns do not count towards the limitation of 900 byte key size or 16-columns that exists in SQL Server. The non-key columns can use data types not allowed by index key columns; all data types except the legacy text, ntext, and image are supported. Additionally, in SQL Server 2008, varbinary (max) columns that have the FILESTREAM attribute cannot be included in an index. While the new large object (LOB) data types are supported as non-key columns, there are performance implications with maintaining the included columns, since the column values are copied into the leaf level of the non-clustered index that contains them. This will result in high disk space requirements to store the index, and also an increase in I/O demands and lower buffer cache efficiency.

    Once again, the degree to which you use included columns in your indexing strategy for a database depends on the usage characteristics of that database. The gains in query performance that included columns can provide must be balanced against the cost of higher disk space requirements, lower cache efficiency, and reduced performance of data modification operations. In data warehouse environments, it may be acceptable to have non-clustered indexes with long included column lists to cover the queries that may be executed, if during the extract-transform-load process (ETL) the indexes may be disabled or dropped to eliminate the impact of index maintenance during the data loading. In contrast, transactional databases would generally use fewer included columns due to the impact on the performance of data manipulation operations.

    Creating a covering index for a query can be one of the best ways to get a query to perform well, however not all queries can be covered, and not all queries should be covered. In an OLTP environment, this is something that should be considered only for critical queries, i.e. queries that execute often and must run as fast as possible. Trying to cover all queries that run in an environment is almost certain to bloat the database size significantly and have detrimental effects on data modification performance.

    So, given that, let's take one of the earlier examples from AdventureWorks and see how we can use included columns to make the query in Listing 5.5 even more efficient.

    SELECT  BusinessEntityID ,
            FirstName ,
            LastName
    FROM    Person.Person AS p
    WHERE   PersonType = 'GC'
            AND Title = 'Ms.'

    Listing 5.5: An AdventureWorks query.

    The index that we decided on for this query is shown in Listing 5.6.

    CREATE INDEX idx_Person_TypeTitle
    ON Person.Person (Title, PersonType)
    
    Listing 5.6: A non-covering index.
    
    That index does not cover the query. While it has all the columns needed for the WHERE clause, it does not have as part of the index the three columns in the SELECT. SQL Server will have to do a lookup to the clustered index to fetch those columns.

    Now, if we were to add those three columns to this index it would make the index covering for this query. We don't want them as key columns; doing so would make the key unnecessarily wide. Since those columns are not being filtered or joined on, there is no need to have them as key columns, so we can make them included columns instead, as shown in Listing 5.7.

    CREATE INDEX idx_Person_TypeTitle
    ON Person.Person (Title, PersonType)
    INCLUDE (BusinessEntityID, FirstName, LastName)

    Listing 5.7: Adding included columns to cover a query.

    Now the index contains all the columns needed for the query, and the query is as efficient as possible since it no longer needs to do lookups. The trade-off is that the index is slightly larger and that data modifications that affect any of the three include columns have more work to do.

    Index width

    There is no strict rule governing the width of an index, and we won't discuss the topic in detail here. However, in general, you want the index to be as narrow as possible while still achieving accurate search results. This means that indexes will ideally comprise as few columns as is practical, consisting of smaller rather than larger data types. Of course, the latter is rather dependent on how intelligently the underlying tables have been designed.

    While you certainly don't want any columns to be part of the key that don't need to be there, neither is it at all wise to opt for a large number of single-column indexes. Gail Shaw discusses the topic of a single multi-column index versus multiple single-column indexes in further detail on her blog post, One wide index or multiple narrow indexes? (http://sqlinthewild.co.za/index.php/2010/09/14/one-wide-index-or-multiplenarrow-indexes/), proving in her example that the single, multi-column index is the best approach.

    Identifying Missing Indexes

    SQL Server 2005 and later offers a number of features that can help identify indexes that may be beneficial to the performance of a specific workload or query.

    •	 Database Engine Tuning Advisor – a vastly-improved and expanded version of the old Index Tuning Wizard, the DTA analyses the execution plans generated for a supplied workload, along with the physical characteristics of the database, and recommends a set of indexes.

    •	 Missing Index feature – during query optimization, the Query Optimizer identifies indexes that it thinks would have been beneficial to the performance of the specific query being optimized. This information is stored in two places:

    •	 the Missing Index Dynamic Management Views – a group of four DMVs, identified
    by sys.dm_db_missing_index_*, where* is details, columns, group_stats or groups

    •	 XML showplans – missing index information can also be extracted from the MissingIndexGroup element of these showplans.

    It is important to keep in mind that, while these features can be very useful in determining the indexes that may be beneficial to your databases, they can also be a doubleedged sword and do more harm than good when used incorrectly. Blindly implementing the recommendations of any of these features will almost always result in duplicate or overlapping indexes in the database, as well as too many, rather than too few, indexes.

    Workload analysis with the Database Engine Tuning Advisor

    One of the easiest ways to identify the missing indexes for a SQL database, if you don't understand the concepts behind index selection well enough to create indexes manually, is to make use of the Database Engine Tuning Advisor (DTA).

    The DTA can be used to analyze a single query or an entire database workload, in the form of a trace file generated by SQL Server Profiler. Of course, this means that the quality of the DTA's index analysis will only be as high as the quality of the workload that is provided to the tool for analysis. If the workload is non-representative of the typical workload for that database, and is missing significant queries, then the index suggestions will likewise be incomplete, inaccurate, or just plain wrong.

    Collecting a workload trace

    To get the best results and recommendations from the DTA, the workload trace must contain a significant portion of the standard workload for the database being analyzed. As part of its analysis, the DTA estimates the impact of any suggested index changes on the performance of the workload as a whole. This helps it avoid recommending an index that boosts performance for a certain individual query but has an overall negative impact on the workload. As such, if you provide a single query to the DTA for analysis, the recommendations provided by the DTA can be very different from what would be recommended if the same query was analyzed as a part of a complete workload for the database.

    SQL Server Profiler supplies a built-in SQL Trace template, the Tuning template, which is designed to capture the necessary events for a workload for analysis by the DTA. To use this template, open SQL Server Profiler and connect to the SQL Server instance. In the Trace Properties window (Figure 5.1) select the Tuning template in the Use the template dropdown.

    Figure 5.1: SQL Profiler – Trace Properties window.

    It is possible to run the tuning trace directly from SQL Profiler and have it save the captured events to a file, or trace table, However, collecting client-side Profiler traces can cause performance deterioration of the server under analysis, due to the additional cost of buffering the events to memory and the network traffic required to send the events to SQL Server Profiler using the rowset provider.

    Impact of the rowset provider on Profiler performance

    For further information and analysis of this topic, see SQL Server MVP Grant Fritchey's blog post, "Profiler Research" at (http://www.scarydba.com/2008/12/18/profiler-research/).

    A much better way to capture a workload trace file for analysis by the Database Tuning Advisor is to script the trace definition on the client machine, using Profiler, but then run the trace server-side. To script the trace definition, manually start the tuning trace within Profiler, but then immediately stop it. Next, from the Export option in the File Menu, select Script Trace Definition | For SQL Server 2005 – 2008 (Figure 5.2).

    Figure 5.2: SQL Profiler – Script Trace Definition

    This saves a trace definition (.sql) file containing all the code necessary to create and start a server-side trace. This generated trace file can be edited as necessary, then run manually, or scheduled as needed. Open the file in SSMS to edit it. Firstly, replace the @FileName variable with the path and file name to be created on the server, and then execute the script to start the trace (in Listing 5.8, add the path and file name where the script says 'InsertFileNameHere'). Only the file name is necessary, as the .trc extension will be added automatically.

    Once the file has been saved, open the file in SQL Server Management Studio and edit it. Next, change the @maxfilesize variable to a size that makes sense, based on the level of activity of the database being traced. Additional options exist for the trace definition, which are not included as a part of the scripted definition provided by SQL Profiler. The @stoptime parameter of sp_trace_create can be used to specify an automatic stop time for the trace collection. The @filecount parameter can be used to specify the number of rollover files to maintain for the trace if the @options parameter has been configured to allow rollover to occur.

    When these additional options are specified, they must be specified in the exact order that is listed in the Books Online topic for sp_trace_create (http://msdn.microsoft.com/en-us/library/ms190362.aspx).

    The finished script, shown in Listing 5.8, will output the traceid of the trace being created, allowing it to be stopped and deleted using sp_trace_setstatus once the collection period has completed.

    DECLARE @rc INT
    DECLARE @TraceID INT
    DECLARE @maxfilesize BIGINT
    SET @maxfilesize = 50
    EXEC @rc = sp_trace_create @TraceID OUTPUT, 0, N'InsertFileNameHere',
        @maxfilesize, NULL
    IF ( @rc != 0 )
        GOTO error
    -- Client side File and Table cannot be scripted
    -- Set the events
    DECLARE @on BIT
    SET @on = 1
    EXEC sp_trace_setevent @TraceID, 137, 15, @on
    EXEC sp_trace_setevent @TraceID, 137, 1, @on
    EXEC sp_trace_setevent @TraceID, 137, 13, @on

    -- Set the Filters
    DECLARE @intfilter INT
    DECLARE @bigintfilter BIGINT
    -- Set the trace status to start
    EXEC sp_trace_setstatus @TraceID, 1
    -- display trace id for future references
    SELECT TraceID = @TraceID
    GOTO finish
    error:
    SELECT ErrorCode = @rc
    finish:
    go

    Listing 5.8: The complete, edited server-side tuning trace.

    Analyzing a trace workload

    The DTA can be opened from the Tools menu in SQL Server Management Studio; a new tuning session is started automatically and the captured workload file can be uploaded. The tuning session configuration screen has two tabs: General and Tuning Options. The General tab (Figure 5.3) contains the name of the session that is running the DTA, the type of workload to be consumed, the source location for the workload, a dropdown for selecting the database to be analyzed, and a grid view to allow the selection of specific databases and tables to tune based on the workload.

    Figure 5.3: Database Tuning Advisor – General tab.

    The Tuning Options tab (Figure 5.4) contains the options that will be used during the tuning analysis of the workload. Depending on the size of the workload trace file, the tuning analysis may run for a long time. The Limit tuning time check box allows specification of a stop time for the analysis.

    In the following sections, you can specify the Physical Design Structures to be used by the DTA when making recommendations (in this case indexes), whether or not partitioning should be used, and which existing Physical Design Structures to keep in the database.

    The Advanced Options button allows you to define the maximum disk space, in megabytes, that can be used to store the various recommendations, as well as whether or not the indexing recommendations are made for online or offline operations.

    Figure 5.4: Database Tuning Advisor – Tuning Options tab.

    Once the appropriate options have been set, you can start the index analysis by clicking Start Analysis in the DTA menu bar, and the DTA will begin analyzing the workload. During this analysis, it will create and drop hypothetical indexes and statistics and perform what-if analysis of the impact of each. The DTA tuning log will track the progress of the tuning session, if the option was left checked on the General tab of the DTA, and will output messages as the session progresses.

    Reviewing index recommendations

    When the tuning session completes, the DTA's recommendations regarding indexes and associated statistics will populate the Recommendations tab (Figure 5.5). These recommendations can be saved to a file for manual application at a later point in time or applied immediately to the database by selecting the appropriate option in the Actions menu. Additionally, the DTA provides the ability to perform another what-if analysis of a subset of the recommendations, allowing you to determine the impact to the estimated improvement caused by removing (unchecking) some of the recommendations from the analysis set. It is strongly recommended that any index recommendations made by the DTA be tested in an isolated test environment before implementing them in production. You can do this either manually, or by using the Actions | Evaluate Recommendations option of the DTA to apply the changes, and then evaluating their true impact by rerunning the tuning analysis of the workload.

    Figure 5.5: Database Tuning Advisor – Recommendations tab.

    Missing index feature

    In SQL Server 2005 and later, the database engine tracks information about indexes that do not exist but that the optimizer could have used during query plan optimization to improve the performance of a particular SQL statement.

    This information is stored in the missing index DMVs, and in the MissingIndexGroup element of the XML showplan for a query, and can, in theory, be used to identify and create beneficial indexes.

    It is undoubtedly a useful feature, but I will state up front that if you blindly create all the indexes recommended by this missing index feature, you will likely do more harm than good to your database performance. The biggest problem is that, unlike those arising from the DTA, these missing index recommendations are not workload based; they are derived from the execution of individual queries and take no account of other index recommendations arising from the execution of other queries. As such, it is very common for the missing index feature to recommend overlapping and even duplicate indexes.

    However, when used with due care, the missing index feature can help you to discover the few indexes that really could make a big difference to the overall performance of your workload, or those indexes that, with a small tweak to their definition, would cover many more queries.

    Missing index DMVs

    The fastest way to retrieve the information related to missing indexes, as identified by the query optimizer, is to query the missing index DMVs. There are four DMVs associated with the missing index feature in SQL Server:

    •	 sys.dm_db_missing_index_details – stores detailed information regarding indexes the optimizer would have used had they been available, such as columns that could have been used to resolve equality or inequality predicates, and suggested INCLUDE columns for covering a query.

    •	 sys.dm_db_missing_index_columns – accepts an index_handle and returns a list of columns that would comprise the suggested index.

    •	 sys.dm_db_missing_index_group_stats – returns summary information regarding the potential benefit of a "missing" index, based, for example, on the number of seeks and scans that would have benefited.

    •	 sys.dm_db_missing_index_groups – a join view between _group_stats and _index_details.

    These views, when joined together, can identify missing indexes and provide the cost reduction, estimated by the optimizer, if the index was created. The sys.dm_db_missing_index_group_stats and sys.dm_db_missing_index_groups views, despite their names, do not actually contain groups of indexes; the groups (as of SQL Server 2008 R2) relate to only one missing index tracked in the system.

    The information stored in these DMVs is certainly useful, but there are a number of limitations that you need to consider when basing your index choices on this data, including the following:

    •	 the information contained in these DMVs is in volatile storage; meaning that it only exists in memory and doesn't exist beyond SQL service restarts, or changes to a database state like restoring the database, detaching the database, taking the database offline, or the database being closed by the AutoClose option.

    •	 statistics are only stored for a maximum of 500 missing index groups.

    •	 index key columns, specified by the equality and inequality column outputs of the sys.dm_db_missing_index_details and sys.dm_db_missing_index_columns DMVs, are not ordered according to cardinality.

    As previously discussed in this chapter, it is often (though not always) best to order the index key columns such that the most selective column is the first column in the index. This reduces the number of database pages that must be read by the database engine while traversing the index, in order to satisfy the query.

    However, unlike the DTA recommendations, the missing index recommendations stored in the DMVs do not consider key column cardinality; in other words, they are not based on the data contained in the key columns that it is recommending be created. As such, it is necessary to perform additional manual analysis of the key column cardinality in order to arrive at the optimal index structure.

    These limitations mean that this tool is best used to identify gaping holes in an indexing strategy, rather than as a fine-tuning tool. The recommended approach is to identify potentially useful indexes, listing first those that offer the biggest potential performance benefit according to the metrics stored in the sys.dm_missing_index_group_stats DMV.

    For example, in the sys.dm_missing_index_group_stats DMV, the user_seeks and user_scans columns provide the number of seek and scan operations that would have benefited from a particular index recommendation. The avg_total_user_cost column provides the average reduction in query cost as a result of creating the index, and the avg_user_impact column provides the percent reduction in query cost, had the index existed.

    Together, these columns can be used to generate an overall estimated performance improvement associated with a specific missing index in the database. There are several ways to calculate this estimated performance improvement, but the generally accepted formula, shown in Listing 5.9, was provided by kind permission of Bart Duncan, one of the members of the SQL Server product team at Microsoft, from his MSDN blog post, Are you using SQL's Missing Index DMVs? (http://blogs.msdn.com/b/bartd/archive/2007/07/19/are-you-using-sql-s-missing-index-dmvs.aspx).

    SELECT  migs.avg_total_user_cost * ( migs.avg_user_impact / 100.0 )
            * ( migs.user_seeks + migs.user_scans ) AS improvement_measure ,
            'CREATE INDEX [missing_index_'
            + CONVERT (VARCHAR, mig.index_group_handle) + '_'
            + CONVERT (VARCHAR, mid.index_handle) + '_'
            + LEFT(PARSENAME(mid.statement, 1), 32) + ']' + ' ON '
            + mid.statement184
            Chapter 5: Missing Indexes
            + ' (' + ISNULL(mid.equality_columns, '')
            + CASE WHEN mid.equality_columns IS NOT NULL
                        AND mid.inequality_columns IS NOT NULL THEN ','
                   ELSE ''
              END + ISNULL(mid.inequality_columns, '') + ')'
                                                   + ISNULL(' INCLUDE ('
                                                      + mid.included_columns
                                                      + ')', '')
                                                  AS create_index_statement ,
            migs.* ,
            mid.database_id ,
            mid.[object_id]
    FROM    sys.dm_db_missing_index_groups mig
            INNER JOIN sys.dm_db_missing_index_group_stats migs
                   ON migs.group_handle = mig.index_group_handle
            INNER JOIN sys.dm_db_missing_index_details mid
                   ON mig.index_handle = mid.index_handle
    WHERE   migs.avg_total_user_cost * ( migs.avg_user_impact / 100.0 )
            * ( migs.user_seeks + migs.user_scans ) > 10
    ORDER BY migs.avg_total_user_cost * migs.avg_user_impact
                 * ( migs.user_seeks + migs.user_scans ) DESC

    Listing 5.9: Identifying missing indexes based on query cost benefit.

    The calculated improvement_measure column provides the estimated improvement value of each index recommendation, based on the average total reduction in query cost that would result, the number of seek and scan operations that could be satisfied by the index, and the percentage benefit the index would provide to the queries being executed. This column makes it easier to focus on those indexers that offer the biggest cost benefit.

    When analyzing the output of this query, I focus on the indexes with an impact value higher than 50,000. I then analyze the recommendations carefully, since it's likely that there will be a degree of overlap among the recommended indexes, with several indexes differing only subtly in terms of their index key column definitions and column orders, or included column definitions and orders. It's also likely that I can derive similar performance benefit by modifying an existing index rather than creating a new one. As discussed previously in the Index Selection and Design section, every index should be tested, to ensure that it really is useful, before deploying it to production. The goal is to create as few indexes as possible that will satisfy as many as possible of the most significant queries that comprise the SQL Server workload.

    Missing index information in XML showplans

    When the query optimizer identifies a missing index during query plan generation, it also stores this information within the ShowPlan XML data. This means that we can retrieve this information for any execution plan in the plan cache, with the added bonus that we can tie individual missing index recommendations directly to the statements and execution plans that generated them. If the query that instigated the index recommendation is one that occurs frequently in our normal workload, then it is much more likely to offer a real performance benefit than a recommendation arising from a "one-off" query.

    The only downside is that there is often a substantial CPU cost associated with queries that search the plan cache for the entries that contain missing index information, and then shred the ShowPlan XML data to retrieve the actual missing index information.

    The ShowPlan XML in SQL Server is a schema-bound XML document, based on Microsoft's published schema (http://schemas.microsoft.com/sqlserver/2004/07/showplan). A review of the ShowPlan XML schema reveals that the missing index information is captured in the XML document as a complex type, under the <MissingIndexGroup/> element. A deeper analysis shows that this complex type can only occur under the <QueryPlan/> element with a distinct and predictable relative path. Using this predictable relative path, the individual missing index recommendations can be parsed out of the plan cache and then sub-parsed using XQuery inside of SQL Server, as demonstrated in Listing 5.10.

    ;
    WITH XMLNAMESPACES
      (DEFAULT 'http://schemas.microsoft.com/sqlserver/2004/07/showplan')
    SELECT MissingIndexNode.value('(MissingIndexGroup/@Impact)[1]', 'float')
                                                                AS impact ,
           OBJECT_NAME(sub.objectid, sub.dbid) AS calling_object_name ,
           MissingIndexNode.value
                ('(MissingIndexGroup/MissingIndex/@Database)[1]',
                 'VARCHAR(128)') + '.'
           + MissingIndexNode.value
                ('(MissingIndexGroup/MissingIndex/@Schema)[1]',
                 'VARCHAR(128)') + '.'
           + MissingIndexNode.value
                ('(MissingIndexGroup/MissingIndex/@Table)[1]',
                 'VARCHAR(128)') AS table_name ,
           STUFF(( SELECT ',' + c.value('(@Name)[1]', 'VARCHAR(128)')
                   FROM MissingIndexNode.nodes
                         ('MissingIndexGroup/MissingIndex/
                            ColumnGroup[@Usage="EQUALITY"]/Column')
                        AS t ( c )
                FOR
                  XML PATH('')
                ), 1, 1, '') AS equality_columns ,
           STUFF(( SELECT ',' + c.value('(@Name)[1]', 'VARCHAR(128)')
                   FROM MissingIndexNode.nodes
                         ('MissingIndexGroup/MissingIndex/
                            ColumnGroup[@Usage="INEQUALITY"]/Column')
                        AS t ( c )
                FOR
                  XML PATH('')
                ), 1, 1, '') AS inequality_columns ,
           STUFF(( SELECT ',' + c.value('(@Name)[1]', 'VARCHAR(128)')
                   FROM MissingIndexNode.nodes
                         ('MissingIndexGroup/MissingIndex/
                            ColumnGroup[@Usage="INCLUDE"]/Column')
                        AS t ( c )
                FOR
                  XML PATH('')
                ), 1, 1, '') AS include_columns ,
           sub.usecounts AS qp_usecounts ,
           sub.refcounts AS qp_refcounts ,
           qs.execution_count AS qs_execution_count ,
           qs.last_execution_time AS qs_last_exec_time ,
           qs.total_logical_reads AS qs_total_logical_reads ,
           qs.total_elapsed_time AS qs_total_elapsed_time ,
           qs.total_physical_reads AS qs_total_physical_reads ,
           qs.total_worker_time AS qs_total_worker_time ,
           StmtPlanStub.value('(StmtSimple/@StatementText)[1]', 'varchar(8000)') AS
    statement_text
    FROM   ( SELECT ROW_NUMBER() OVER
                                 ( PARTITION BY qs.plan_handle
                                   ORDER BY qs.statement_start_offset )
                                   AS StatementID ,
                      qs.*
           FROM       sys.dm_exec_query_stats qs
          ) AS qs
          JOIN ( SELECT   x.query('../../..') AS StmtPlanStub ,
                          x.query('.') AS MissingIndexNode ,
                          x.value('(../../../@StatementId)[1]', 'int')
                                                         AS StatementID ,
                          cp.* ,
                          qp.*
                 FROM     sys.dm_exec_cached_plans AS cp
                          CROSS APPLY sys.dm_exec_query_plan
                                                  (cp.plan_handle) qp
                          CROSS APPLY qp.query_plan.nodes
                                       ('/ShowPlanXML/BatchSequence/
                                          Batch/Statements/StmtSimple/
                                          QueryPlan/MissingIndexes/
                                          MissingIndexGroup') mi ( x )
                ) AS sub ON qs.plan_handle = sub.plan_handle
                            AND qs.StatementID = sub.StatementID

    Listing 5.10: Parsing missing index information out of XML showplans.

    This code example will return a similar output to the raw information provided by the missing index DMVs, with the exception that this output will also include the statement text from the plan cache and the associated execution statistics, which are tracked by the sys.dm_exec_query_stats DMV.

    This level of detail allows for a more focused implementation of the missing index details than is easily available through the missing index DMVs, based on knowledge of the actual SQL statement that was executed in order to generate the index recommendation, as well as information about the query execution stats and impact on the system.

    As discussed earlier, this analysis is not free; shredding the XML from the plan cache can be an expensive operation, especially on servers with large amounts of memory installed, and can significantly increase CPU usage.

    To minimize the impact on a production server, the execution plans containing the missing index XML nodes can be written to a table, which can then be transferred to a development or test server to perform the XML shredding operation.

    Missing indexes on foreign keys

    A very common source of performance issues in a SQL Server database is a lack of indexes on FOREIGN KEY columns, which are commonly used to join two tables together. Generally speaking, FOREIGN KEY columns represent parent/child relationships between two tables as one-to-many relationships.

    A good rule of thumb is for any FOREIGN KEY columns that are commonly used in JOIN operations to have an associated index, either with the FOREIGN KEY column as the leading column in the index, or as a column further down the index key, depending on the queries.

    The code in Listing 5.11 can be used to identify non-indexed FOREIGN KEY columns in a database. The query will match the FOREIGN KEY column to any index with the same column on the same table and returns columns with no matches at all. For a database that is using single-column PRIMARY KEYs, this code can be very effective at identifying any FOREIGN KEY that is potentially problematic for performance, due to the lack of a supporting index on the JOIN. However, for a database with any composite multi-column PRIMARY KEYs, the script will be only partially helpful since it doesn't check the existence of all of the columns within the same index. For more complex key sets, this code can be modified to return information about all of the FOREIGN KEY columns in the database to allow manual validation of the indexing of these keys.

    SELECT  fk.name AS CONSTRAINT_NAME ,
            s.name AS SCHEMA_NAME ,
            o.name AS TABLE_NAME ,
            fkc_c.name AS CONSTRAINT_COLUMN_NAME
    FROM sys.foreign_keys AS fk
            JOIN sys.foreign_key_columns AS fkc
                  ON fk.object_id = fkc.constraint_object_id
            JOIN sys.columns AS fkc_c
                  ON fkc.parent_object_id = fkc_c.object_id
                                  AND fkc.parent_column_id = fkc_c.column_id
            LEFT JOIN sys.index_columns ic
            JOIN sys.columns AS c ON ic.object_id = c.object_id
                                     AND ic.column_id = c.column_id
                                      ON fkc.parent_object_id = ic.object_id
                                      AND fkc.parent_column_id = ic.column_id
            JOIN sys.objects AS o ON o.object_id = fk.parent_object_id
            JOIN sys.schemas AS s ON o.schema_id = s.schema_id
    WHERE c.name IS NULL

    Listing 5.11: Identifying single-column, non-indexed FOREIGN KEYs.

    Identifying Unused Indexes

    One of the side effects of adding and modifying indexes in a user database is the possibility that existing indexes stop being used by SQL Server. These unneeded database artifacts offer no benefit in terms of query performance but continue to consume additional I/O operations during data manipulation operations, since any change to the underlying data must also be made to the corresponding data stored in the index. The sys.dm_db_index_usage_stats DMV in SQL Server 2005 and 2008 provides a mechanism to determine how individual indexes in a specific database have been used.

    This DMV provides information about the number of user_seeks, user_scans, user_lookups, and user_updates that have been performed against each of the indexes inside a specific database. However, the information contained in the DMV is not persisted and the DMV data is lost whenever the instance is restarted, or the database state changes, for example, being taken offline, restored, detached, or closed. For this reason, the index usage statistics should only be evaluated when the database has been online and under a standard workload that would make use of the indexes that are being evaluated.

    What we are looking for, with the query shown in Listing 5.12, is any non-clustered index that has never been used for a seek, scan, or lookup operation by SQL Server, but is associated with a significant number of update operations. These indexes can be considered to be unused and should be dropped from the database.

    SELECT  OBJECT_SCHEMA_NAME(i.object_id) AS SchemaName ,
            OBJECT_NAME(i.object_id) AS TableName ,
            i.name ,
            ius.user_seeks ,
            ius.user_scans ,
            ius.user_lookups ,
            ius.user_updates
    FROM sys.dm_db_index_usage_stats AS ius
            JOIN sys.indexes AS i ON i.index_id = ius.index_id
                                AND i.object_id = ius.object_id
    WHERE   ius.database_id = DB_ID()
            AND i.is_unique_constraint = 0 -- no unique indexes
            AND i.is_primary_key = 0
            AND i.is_disabled = 0
            AND i.type > 1 -- don't consider heaps/clustered index
            AND ( ( ius.user_seeks + ius.user_scans +
                     ius.user_lookups ) < ius.user_updates
                  OR ( ius.user_seeks = 0
                       AND ius.user_scans = 0
                     )
               )

    Listing 5.12: Finding unused non-clustered indexes.

    Note again that this code should only be used when the database has been online for a significant period of time, in order to ensure that the appropriate workload has been executed. Certain indexes may be used infrequently but when they are required, such as when the weekly, monthly, or even quarterly reporting operations are run, they are vital!

    Identifying Duplicate Indexes

    Duplicate indexes in a database incur maintenance costs that waste valuable resources on a server. The process of identifying true duplicate indexes in SQL Server is nontrivial at best and incredibly complex when you begin to account for various cases where seemingly duplicate indexes actually aren't duplicate, due to the width and selectivity of the indexes.

    Duplicate indexes are primarily a concern for OLTP systems where the performance of INSERT operations is paramount, whereas for data warehouse systems the performance of SELECT operations is critical, data loading occurs less frequently, and so one can have a higher level of tolerance to duplicate indexes.

    Many online articles state, incorrectly, that the key columns are the primary point of analysis when identifying duplicate indexes in a database. The truth is that two indexes can have similar key columns, but different width, selectivity, and purpose in a database, and so not be duplicate indexes. To fully identify an index as a duplicate, the leaf level of the index must be investigated to identify which columns are maintained at the leaf level, which also maintains the included columns in the index. Key column order at the leaf level matters, but included column order for the index does not.

    Complications of identifying duplicate indexes in SQL Server

    In her following two blog posts, Kimberly Tripp offers further insight into the complications of identifying duplicate indexes, and provides a stored procedure for identifying and removing them: "How can you tell if an index is REALLY a duplicate?" (http://sqlskills.com/BLOGS/KIMBERLY/post/UnderstandingDuplicateIndexes.aspx) and "Removing duplicate indexes" (http://sqlskills.com/BLOGS/KIMBERLY/post/RemovingDuplicateIndexes.aspx).
    
    Summary

    Missing indexes in a SQL Server database can lead to many performance-related problems, including higher than necessary disk I/O operations, excessive CPU usage, caused by unnecessary sort operations, and reduced performance.

    Periodic analysis of missing index information, using the available features in SQL Server, will help ensure that the current indexing strategy meets the requirements of the database and the workload being executed. However, due care must be taken when implementing the indexing recommendations made by these features, to ensure that the number of overlapping and duplicated indexes are minimized and that each index created really will have a positive performance benefit. In this way, we can maximize query performance while minimizing the performance impact on data modifications that can arise from over-indexing the tables in a user database.
</body>
</html>